{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains the full pipeline for our submissions to the 2018 VarDial Evaluation Campaign, in particular to the shared task for Discriminating between Dutch and Flemish in subtitles (DFS). We are participating only in the closed training track. See [the official page](http://alt.qcri.org/vardial2018/index.php?id=campaign) for more info.\n",
    "\n",
    "Running the whole stack takes a really long time, especially tuning the parameters for the models, the stacks and blends. There is a cache mechanism in place, so you don't have run it all yourself.\n",
    "\n",
    "In this notebook we run pipelines for the following features, or any combination thereof: word $n$-grams, character $n$-grams, [part of speech $n$-grams](#pos_features), [loglikelihood of $n$-grams](#llh_features), [compression rate](#compression_features), [language models](#lm_features), [word embeddings](#embedding_features). We run most of them through multiple learners, such as xgboost, random forests, linear svc, $k$ nearest neighbours, stochastic gradient descent with multiple objectives, naive bayes, nbsvm, and others. Desperate times call for desperate measures. That's why we also [blend, stack, ensemble, #insertbuzzword](#ensemble). Especially if different learners achieve a decent score, but their results have little correlation, we expect a lot of combining the models. This is also the way to win Kaggle competitions, so yes, surely one can win this shared task this way as well. Right? (right?)\n",
    "\n",
    "There's not much background literature involved. I mean, the reference in the [literature list](https://github.com/naiaden/lama-dsl/blob/master/literature.md) don't seem to be that surprising. It also appears to be an intrinsically hard task. As a human. I think that there's also a very low human annotater agreement if one were to test this. This would then suggest that the performance ceiling is very low (I suspect around 75%, or even less). On development data we can reach around 70% accuracy (this is not the final number), so I think we're doing okayist. But I am also absolutely clueless of the competition. They will probably outwit me in imaginary ways. That'd be nice.\n",
    "\n",
    "So let's get this notebook running. The first couple of page scrolls are filled with the boring stuff. After that is the less boring, but still boring stuff. It's the actual learning at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ucto\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can enter the parts that you want to run. The identifiers are the run names, and you can find them further\n",
    "in the notebook. Use \"all\" to run all of them; this option overrules all other run names. Also note that it takes a\n",
    "seriously large amount of time to run them all.\n",
    "\n",
    "Most of the times we don't run the experiments from the notebook, but from the console, so we're doing a little testing and flagging here to make sure we show the proper output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "_run = set([])\n",
    "_data_mode = \"test-dev\" # test-dev, subset-dev, cv, test\n",
    "_show_graphics = True\n",
    "\n",
    "import sys\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    # running in console\n",
    "    _show_graphics = False\n",
    "    from tqdm import tqdm as tqdm, trange as tnrange\n",
    "    \n",
    "    for v in sys.argv:\n",
    "        if v.startswith(\"r:\"):\n",
    "            _run.add(v[2:])\n",
    "        elif v == \"o:subset\":\n",
    "            _data_mode = \"subset-dev\"\n",
    "        elif v == \"o:cv\":\n",
    "            _data_mode = \"cv\"\n",
    "        elif v == \"o:test\":\n",
    "            _data_mode = \"test\"\n",
    "            \n",
    "else:\n",
    "    # running in notebook\n",
    "    from tqdm import tqdm_notebook as tqdm, tnrange as tnrange\n",
    "    \n",
    "    #_run.add(\"all\")\n",
    "    \n",
    "    _use_subset = True\n",
    "    pass\n",
    "\n",
    "def do_run(name, force=False):\n",
    "    if force:\n",
    "        return True\n",
    "    \n",
    "    if name in _run or \"all\" in _run:\n",
    "        return True\n",
    "    \n",
    "#     try:\n",
    "#         if name not in _run_stats:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not going to do that much with confusion matrices, but they are a helpful tool in determining the true and false positives, and true and false negatives. We only/all want true positives. At least I do. Wikipedia says sensitivity and specificity. But that reads like a Jane Austen novel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6196d11e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "                      \n",
    "cm = confusion_matrix(['BEL', 'BEL', 'DUT', 'DUT', 'BEL', 'DUT', 'DUT', 'DUT', 'DUT', 'DUT'],  # golden truth\n",
    "                      ['BEL', 'DUT', 'DUT', 'BEL', 'DUT', 'DUT', 'BEL', 'BEL', 'DUT', 'DUT'])  # our predictions\n",
    "\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "labelEncoder.fit([\"BEL\", \"DUT\"])\n",
    "\n",
    "if _show_graphics:\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes=labelEncoder.classes_, title=\"My first confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for this example, we assume that in this binary classification task we have to predict whether it's a Flemish subtitle or not. That means that Flemish is the positive class, and Netherlandic the negative class. (I obviously don't agree, but since I'm also connected to the KU Leuven, I can live with this.) Then if we properly classified the Flemish subtitle as a Flemish subtitle, it's a true positive. In this case we found 1. On the other hand we can also correctly guess that a negative example is indeed a Netherlandic subtitle. That's a true negative, and we've found 4 of them. The other two classes are confusion, be it a Flemish subtitle confused for a Netherlandic subtitle (2 out of 10 cases; false positives), or Netherlandic subtitles confused as Flemish subtitles (3 out of 10 cases; false negatives). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keep track of the runs, especially the best run of a series, its output and its parameters. To this end we have a little structure here to keep them all in one place. You have to call the functions in the order as they are defined. First you register the run with a unique name (or rather, all runs with the same name have their results merged), then you can update its statistics, and at any point you can ask for a summary of the run. One of the feats is that it will show one of those fancy confusion matrices for you. The last function is summarise_all. This one presents you with a nice goodnight story. Yes. It'll make you yawn and fall asleep. Impressed though, you will fall asleep impressed by the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_run_stats = {}\n",
    "\n",
    "import os.path\n",
    "def register_run(name, description, params):\n",
    "    if name not in _run_stats:\n",
    "        # if can be loaded from file\n",
    "        if os.path.exists('cache/' + name + '.json'):\n",
    "            with open('cache/' + name + '.json', 'r') as f:\n",
    "                run_object = json.load(f)\n",
    "                _run_stats[name] = {}\n",
    "                _run_stats[name]['description'] = run_object['description']\n",
    "#                 _run_stats[name]['params'] = run_object['params']\n",
    "                _run_stats[name]['best'] = run_object['best']\n",
    "                _run_stats[name]['best_predictions'] = np.array(run_object['best_predictions'])\n",
    "#                 print(np.matrix(run_object['best_predictions']))\n",
    "                _run_stats[name]['orig_predictions'] = np.array(run_object['orig_predictions'])\n",
    "                _run_stats[name]['history'] = run_object['history']\n",
    "        else:\n",
    "            _run_stats[name] = {}\n",
    "            _run_stats[name]['description'] = description\n",
    "#             _run_stats[name]['params'] = {}\n",
    "#             for param in params:\n",
    "#                 _run_stats[name]['params'][param] = ''\n",
    "\n",
    "            _run_stats[name]['best'] = 0\n",
    "            _run_stats[name]['best_predictions'] = []\n",
    "            _run_stats[name]['orig_predictions'] = []\n",
    "            _run_stats[name]['history'] = []\n",
    "\n",
    "def update_stats(name, y_test, y_pred, params):\n",
    "    if y_pred:\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        _run_stats[name]['history'].append(accuracy)\n",
    "        if accuracy > _run_stats[name]['best']:\n",
    "            _run_stats[name]['best'] = accuracy\n",
    "    #         for param in params:\n",
    "    #             _run_stats[name]['params'][param] = params[param]\n",
    "            _run_stats[name]['best_predictions'] = y_pred\n",
    "            _run_stats[name]['orig_predictions'] = y_test\n",
    "\n",
    "            with open(\"cache/\" + name + \".json\", 'w') as f:\n",
    "                json.dump({'best_predictions': _run_stats[name]['best_predictions'].tolist(),\n",
    "                           'description': _run_stats[name]['description'],\n",
    "    #                        'params': _run_stats[name]['params'],\n",
    "                           'history': _run_stats[name]['history'],\n",
    "                           'orig_predictions': _run_stats[name]['orig_predictions'].tolist(),\n",
    "                           'best': _run_stats[name]['best']\n",
    "                          }, f)\n",
    "    #         with open('cache/' + name + '.pickle', 'w') as f:\n",
    "    #             pickle.dump(_run_stats[name], f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "def summarise_run(name):\n",
    "    if name not in _run_stats:\n",
    "        print(\"Name %s is not registrered.\" % (name))\n",
    "        return\n",
    "    \n",
    "    print(\"Model:    \\n\\t%s\" % (name))\n",
    "    #print(\"Settings: \\n\\t%s\" % (_run_stats[name]['params']))\n",
    "    print(\"Accuracy: \\n\\t%s\" % (_run_stats[name]['best']))\n",
    "\n",
    "    cm = confusion_matrix(_run_stats[name]['orig_predictions'], _run_stats[name]['best_predictions'])\n",
    "    \n",
    "    if _show_graphics:\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(cm, classes=labelEncoder.classes_, title=name)# + \" \" + str(_run_stats[name]['params']))\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(cm)       \n",
    "\n",
    "def summarise_all():\n",
    "    for name in _run_stats.keys():\n",
    "        summarise_run(name)\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the file with [ucto](https://github.com/proycon/python-ucto) and tokenise it according to its default Dutch tokenisation scheme, which is rule-based\n",
    "and definitely better than a plain whitespace tokeniser from sklearn. Afterwards we concatenate the tokens back to a \n",
    "whitespace seperated line, which can then be normally processed with sklearn's tokenisers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucto_config = \"tokconfig-nld\"\n",
    "tokeniser = ucto.Tokenizer(ucto_config, sentenceperlineinput=True, sentencedetection=False, paragraphdetection=False)\n",
    "\n",
    "def read_data(file):\n",
    "    text = {}\n",
    "    with open(file) as f:\n",
    "        for line in tqdm(f):\n",
    "            sentence, language = line.strip().split(\"\\t\")\n",
    "            tokeniser.process(sentence)\n",
    "\n",
    "            if language not in text:\n",
    "                text[language] = []\n",
    "\n",
    "            current_line = []\n",
    "            for token in tokeniser:\n",
    "                current_line.append(str(token))\n",
    "                if token.isendofsentence():\n",
    "                    #print(current_line)\n",
    "                    text[language].append(\" \".join(current_line))\n",
    "                    current_line = []\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is the first run, then we have to tokenise the text. In other cases we probably have saved a pickled version\n",
    "somewhere. If not, we will tokenise the text anyway. No worries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading development set from pickle.\n",
      "development set\n",
      "\t LAN\t size \t avg length\n",
      "\t BEL \t 250 \t 40.456\n",
      "\t DUT \t 250 \t 40.088\n",
      "Done reading training set from pickle.\n",
      "training set\n",
      "\t LAN\t size \t avg length\n",
      "\t BEL \t 150000 \t 40.273626666666665\n",
      "\t DUT \t 150000 \t 40.37152\n"
     ]
    }
   ],
   "source": [
    "# First the development set\n",
    "try:\n",
    "    with open('data/dev.txt.pickle', 'rb') as f:\n",
    "        _l_dev_text = pickle.load(f)\n",
    "        print(\"Done reading development set from pickle.\")\n",
    "except IOError:\n",
    "    _l_dev_text = read_data('data/dev.txt')\n",
    "    print(\"Done tokenising development set.\")\n",
    "    with open('data/dev.txt.pickle', 'wb') as f:\n",
    "        pickle.dump(_l_dev_text, f, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Done writing development set from pickle.\")\n",
    "\n",
    "print(\"development set\")\n",
    "print(\"\\t LAN\\t size \\t avg length\")\n",
    "for l in _l_dev_text.keys():\n",
    "    print(\"\\t\", l, \"\\t\", len(_l_dev_text[l]), \"\\t\", sum([len(x.split()) for x in _l_dev_text[l]])/len(_l_dev_text[l]))\n",
    "\n",
    "# And then the training set. This takes bit more time...\n",
    "try:\n",
    "    with open('data/train.txt.pickle', 'rb') as f:\n",
    "        _l_trn_text = pickle.load(f)\n",
    "        print(\"Done reading training set from pickle.\")\n",
    "except IOError:\n",
    "    _l_trn_text = read_data('data/train.txt')\n",
    "    print(\"Done tokenising training set.\")\n",
    "    with open('data/train.txt.pickle', 'wb') as f:\n",
    "        pickle.dump(_l_trn_text, f, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Done writing training set from pickle.\")\n",
    "\n",
    "print(\"training set\")\n",
    "print(\"\\t LAN\\t size \\t avg length\")\n",
    "for l in _l_trn_text.keys():\n",
    "    print(\"\\t\", l, \"\\t\", len(_l_trn_text[l]), \"\\t\", sum([len(x.split()) for x in _l_trn_text[l]])/len(_l_trn_text[l]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is as good a time as any to import some random stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib.legend_handler import HandlerLine2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the training and development material into the right shape, and make sure that we also keep track of\n",
    "the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X_training = []\n",
    "_y_training = []\n",
    "for l in _l_trn_text.keys():\n",
    "    for s in _l_trn_text[l]:\n",
    "        _X_training.append(s)\n",
    "        _y_training.append(l)\n",
    "_X_training = np.array(_X_training, dtype=object)\n",
    "_y_training = labelEncoder.transform(_y_training)\n",
    "\n",
    "\n",
    "_X_dev = []\n",
    "_y_dev = []\n",
    "for l in _l_dev_text.keys():\n",
    "    for s in _l_dev_text[l]:\n",
    "        _X_dev.append(s)\n",
    "        _y_dev.append(l)\n",
    "_X_dev = np.array(_X_dev, dtype=object)\n",
    "_y_dev = labelEncoder.transform(_y_dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the features that was promised to deliver mountains of gold, and other glory, such as the first place in whatever context is part of speech tags. We will generate them with [frog](https://github.com/proycon/python-frog). We're not really interested in the full tag, but more so in the head of the tag. That's why it's the only part we're keeping. It's slow. It's faster to generate them yourself than to ask me to mail you them but still. It's slooow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/' + 'dev' + '.POS.txt') or not os.path.exists('data/' + 'train' + '.POS.txt'):\n",
    "    import frog\n",
    "\n",
    "    frog = frog.Frog(frog.FrogOptions(parser=False))\n",
    "\n",
    "    for t in ['dev', 'train']:\n",
    "        with open('data/' + t + '.POS.txt', 'w') as out:\n",
    "            with open('data/' + t + '.txt', 'r') as f:\n",
    "                for line in f:\n",
    "                    sentence, tag = line.strip().split(\"\\t\")\n",
    "                    froggo = frog.process(sentence)\n",
    "                    postext = []\n",
    "                    for w in froggo:\n",
    "                        postext.append(w['pos'].split(\"(\")[0])\n",
    "                    out.write(\" \".join(postext) + \"\\t\" + tag + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the part of speech training material into the same form as two cells up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X_pos_training = []\n",
    "_y_pos_training = []\n",
    "with open('data/train.POS.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        sentence, tag = line.strip().split(\"\\t\")\n",
    "        _X_pos_training.append(sentence)\n",
    "        _y_pos_training.append(tag)\n",
    "_X_pos_training = np.array(_X_pos_training)\n",
    "_y_pos_training = labelEncoder.transform(_y_pos_training)\n",
    "\n",
    "_X_pos_dev = []\n",
    "_y_pos_dev = []\n",
    "with open('data/dev.POS.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        sentence, tag = line.strip().split(\"\\t\")\n",
    "        _X_pos_dev.append(sentence)\n",
    "        _y_pos_dev.append(tag)\n",
    "_X_pos_dev = np.array(_X_pos_dev)\n",
    "_y_pos_dev = labelEncoder.transform(_y_pos_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes for testing whether some code words, you might want to use a subset. Use this one. Or another one. I don't\n",
    "care. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_mode = \"subset-dev\"\n",
    "\n",
    "if _data_mode == \"test-dev\":\n",
    "    X_training = _X_training\n",
    "    y_training = _y_training\n",
    "    X_dev = _X_dev\n",
    "    y_dev = _y_dev\n",
    "    \n",
    "    X_pos_training = _X_pos_training\n",
    "    y_pos_training = _y_pos_training\n",
    "    X_pos_dev = _X_pos_dev\n",
    "    y_pos_dev = _y_pos_dev\n",
    "elif _data_mode == \"subset-dev\":\n",
    "    import random\n",
    "    use = random.sample(range(1, 299999), 500)\n",
    "#     X_training = [_X_training[use]]\n",
    "#     y_training = [_y_training[use]]\n",
    "#     X_dev = [_X_dev]\n",
    "#     y_dev = [_y_dev]\n",
    "    \n",
    "#     X_pos_training = [_X_pos_training[use]]\n",
    "#     y_pos_training = [_y_pos_training[use]]\n",
    "#     X_pos_dev = [_X_pos_dev]\n",
    "#     y_pos_dev = [_y_pos_dev]\n",
    "    X_training = _X_training[use]\n",
    "    y_training = _y_training[use]\n",
    "    X_dev = _X_dev\n",
    "    y_dev = _y_dev\n",
    "    \n",
    "    X_pos_training = _X_pos_training[use]\n",
    "    y_pos_training = _y_pos_training[use]\n",
    "    X_pos_dev = _X_pos_dev\n",
    "    y_pos_dev = _y_pos_dev\n",
    "elif _data_mode == \"test\":\n",
    "#     X_training = [np.concatenate((_X_training, _X_dev))]\n",
    "#     y_training = [np.concatenate((_y_training, _y_dev))]\n",
    "#     X_dev = [np.array([])]\n",
    "#     y_dev = [np.array([])]\n",
    "    \n",
    "#     X_pos_training = [np.concatenate((_X_pos_training, _X_pos_dev))]\n",
    "#     y_pos_training = [np.concatenate((_y_pos_training, _y_pos_dev))]\n",
    "#     X_pos_dev = [np.array([])]\n",
    "#     y_pos_dev = [np.array([])]\n",
    "    X_training = np.concatenate((_X_training, _X_dev))\n",
    "    y_training = np.concatenate((_y_training, _y_dev))\n",
    "    X_dev = np.array([])\n",
    "    y_dev = np.array([])\n",
    "    \n",
    "    X_pos_training = np.concatenate((_X_pos_training, _X_pos_dev))\n",
    "    y_pos_training = np.concatenate((_y_pos_training, _y_pos_dev))\n",
    "    X_pos_dev = np.array([])\n",
    "    y_pos_dev = np.array([])\n",
    "elif _data_mode == \"cv\":\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    X_all = np.concatenate((_X_training, _X_dev))\n",
    "    y_all = np.concatenate((_y_training, _y_dev))\n",
    "    X_training = []\n",
    "    X_dev = []\n",
    "    y_training = []\n",
    "    y_dev = []\n",
    "    \n",
    "    X_pos_all = np.concatenate((_X_pos_training, _X_pos_dev))\n",
    "    y_pos_all = np.concatenate((_y_pos_training, _y_pos_dev))\n",
    "    X_pos_training = []\n",
    "    X_pos_dev = []\n",
    "    y_pos_training = []\n",
    "    y_pos_dev = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_all):\n",
    "        X_training.append(X_all[train_index])\n",
    "        X_dev.append(X_all[test_index])\n",
    "        y_training.append(y_all[train_index])\n",
    "        y_dev.append(y_all[test_index])\n",
    "        \n",
    "        X_pos_training.append(X_pos_all[train_index])\n",
    "        X_pos_dev.append(X_pos_all[test_index])\n",
    "        y_pos_training.append(y_pos_all[train_index])\n",
    "        y_pos_dev.append(y_pos_all[test_index])\n",
    "\n",
    "# print(\"Summary of the training and development (test) data\")\n",
    "# print(\"\\tNumber of sets:   \", len(X_training))\n",
    "# print(\"\\tNumber of examples in X_training: \", [len(x) for x in X_training])\n",
    "# print(\"\\tNumber of labels   in y_training: \", [len(x) for x in y_training])\n",
    "# print(\"\\tNumber of examples in X_dev:      \", [len(x) for x in X_dev])\n",
    "# print(\"\\tNumber of labels   in y_dev:      \", [len(x) for x in y_dev])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count-based features\n",
    "Okay, so let's get the feature engineering started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "features = {}\n",
    "\n",
    "# On the given data\n",
    "\n",
    "features['char_count_vect_1_8'] = {'analyser': CountVectorizer(analyzer='char', ngram_range=(1,8)),\n",
    "                                   'values': {'x_tr': [], 'x_te': []},\n",
    "                                   }\n",
    "\n",
    "features['word_count_vect_1_6'] = {'analyser': CountVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"),\n",
    "                                   'values': {'x_tr': [], 'x_te': []},\n",
    "                                   }\n",
    "\n",
    "features['char_tfidf_vect_1_8'] = {'analyser': TfidfVectorizer(analyzer='char', ngram_range=(1,8)),\n",
    "                                   'values': {'x_tr': [], 'x_te': []},\n",
    "                                   }\n",
    "\n",
    "features['word_tfidf_vect_1_6'] = {'analyser': TfidfVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"),\n",
    "                                   'values': {'x_tr': [], 'x_te': []},\n",
    "                                   }\n",
    "\n",
    "features['woch_tfidf_vect_1_8'] = {'analyser': FeatureUnion([('char', TfidfVectorizer(analyzer='char', ngram_range=(1,8))),\n",
    "                                                             ('word', TfidfVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))]),\n",
    "                                   'values': {'x_tr': [], 'x_te': []},\n",
    "                                   }\n",
    "\n",
    "for feature in features.keys():\n",
    "    features[feature]['values']['x_tr'] = features[feature]['analyser'].fit_transform(X_training)\n",
    "    features[feature]['values']['x_te'] = features[feature]['analyser'].transform(X_dev)\n",
    "\n",
    "# On derivative data\n",
    "\n",
    "features['pos_tfidf_vect_2_6'] = {'analyser': TfidfVectorizer(analyzer='word', ngram_range=(2,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"),\n",
    "                                   'values': {'x_tr': [], 'x_te': []},\n",
    "                                   }\n",
    "features['pos_tfidf_vect_2_6']['values']['x_tr'] = features['pos_tfidf_vect_2_6']['analyser'].fit_transform(X_pos_training)\n",
    "features['pos_tfidf_vect_2_6']['values']['x_te'] = features['pos_tfidf_vect_2_6']['analyser'].transform(X_pos_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLA():\n",
    "    def __init__(self, name, pipeline, parameters, X_training, y_training, verbose=False):\n",
    "        self.name = name\n",
    "        self.pipeline = pipeline\n",
    "        self.parameters = parameters\n",
    "        self.X_training = X_training\n",
    "        self.y_training = y_training\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.fresh_run = not os.path.exists('models/' + self.name + '.sav')\n",
    "    \n",
    "    def __enter__(self):\n",
    "        if self.fresh_run:\n",
    "            print(\"fresh run\")\n",
    "            self.clf = GridSearchCV(self.pipeline, self.parameters, cv=kf, n_jobs=-1)\n",
    "            self.clf.fit(self.X_training, self.y_training)\n",
    "        else:\n",
    "            print(\"from file\")\n",
    "            self.clf = joblib.load('models/' + self.name + '.sav')\n",
    "        return self.clf\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        models[self.name] = {'score': clf.best_score_, 'estimator': clf.best_estimator_}\n",
    "        \n",
    "        if self.fresh_run:\n",
    "            joblib.dump(clf, 'models/' + self.name + '.sav')\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Best parameters set found with gridsearchcv:\")\n",
    "            print(self.clf.best_params_)\n",
    "            print()\n",
    "            means = self.clf.cv_results_['mean_test_score']\n",
    "            stds = self.clf.cv_results_['std_test_score']\n",
    "            for mean, std, params in zip(means, stds, self.clf.cv_results_['params']):\n",
    "                print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                      % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "with BLA('randomforest_wordchar_count',\n",
    "          Pipeline([('union', FeatureUnion([('char', CountVectorizer(analyzer='char', ngram_range=(1,8))),\n",
    "                                            ('word', CountVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))])),\n",
    "                    ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
    "                    ('kbest', SelectKBest()), \n",
    "                    ('rfc', RandomForestClassifier(oob_score = True))]),\n",
    "          {'kbest__k': [10,100, 1000, 10000, 100000, 'all'], \n",
    "                  'rfc__max_features': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                  'rfc__n_estimators': [10, 50, 100, 150, 200, 250],\n",
    "                  'rfc__min_samples_leaf': [1, 5, 10, 25, 50, 75, 100, 250],\n",
    "                  'union__word__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 6)],\n",
    "                  'union__char__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 8)]\n",
    "                  },\n",
    "          X_training,\n",
    "          y_training) as b:\n",
    "    y_t, y_p = y_dev, b.best_estimator_.predict(X_dev)\n",
    "    print(classification_report(y_t, y_p, target_names=labelEncoder.classes_))\n",
    "    print(confusion_matrix(y_t, y_p))\n",
    "    print(\"accuracy: \", accuracy_score(y_t, y_p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "with BLA('multinomialnb_wordchar_count',\n",
    "          Pipeline([('union', FeatureUnion([('char', CountVectorizer(analyzer='char', ngram_range=(1,8))),\n",
    "                                            ('word', CountVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))])),\n",
    "                    ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
    "                    ('kbest', SelectKBest()), \n",
    "                    ('mnb', MultinomialNB())]),\n",
    "          {'kbest__k': [100, 1000, 10000, 1000000, 'all'], \n",
    "                  'mnb__alpha': [0, 0.00001, 0.0001, 0.001, 0.05, 0.5, 1.0, 1.5, 2.5],\n",
    "                  'union__word__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 6)],\n",
    "                  'union__char__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 8)]\n",
    "                  },\n",
    "          X_training,\n",
    "          y_training) as b:\n",
    "    y_t, y_p = y_dev, b.best_estimator_.predict(X_dev)\n",
    "    print(classification_report(y_t, y_p, target_names=labelEncoder.classes_))\n",
    "    print(confusion_matrix(y_t, y_p))\n",
    "    print(\"accuracy: \", accuracy_score(y_t, y_p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "with BLA('sgdhinge_wordchar_count',\n",
    "          Pipeline([('union', FeatureUnion([('char', CountVectorizer(analyzer='char', ngram_range=(1,8))),\n",
    "                                            ('word', CountVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))])),\n",
    "                    ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
    "                    ('kbest', SelectKBest()), \n",
    "                    ('sgd', SGDClassifier(shuffle=True))]),\n",
    "          {'kbest__k': [100, 1000, 10000, 1000000, 'all'], \n",
    "                  'sgd__alpha': 10.0**-np.arange(1,9),\n",
    "                  'union__word__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 6)],\n",
    "                  'union__char__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 8)]\n",
    "                  },\n",
    "          X_training,\n",
    "          y_training) as b:\n",
    "    y_t, y_p = y_dev, b.best_estimator_.predict(X_dev)\n",
    "    print(classification_report(y_t, y_p, target_names=labelEncoder.classes_))\n",
    "    print(confusion_matrix(y_t, y_p))\n",
    "    print(\"accuracy: \", accuracy_score(y_t, y_p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "with BLA('randomforest_wordchar_tfidf',\n",
    "          Pipeline([('union', FeatureUnion([('char', TfidfVectorizer(analyzer='char', ngram_range=(1,8))),\n",
    "                                            ('word', TfidfVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))])),\n",
    "                    ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
    "                    ('kbest', SelectKBest()), \n",
    "                    ('rfc', RandomForestClassifier(oob_score = True))]),\n",
    "          {'kbest__k': [10,100, 1000, 10000, 100000, 'all'], \n",
    "                  'rfc__max_features': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                  'rfc__n_estimators': [10, 50, 100, 150, 200, 250],\n",
    "                  'rfc__min_samples_leaf': [1, 5, 10, 25, 50, 75, 100, 250],\n",
    "                  'union__word__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 6)],\n",
    "                  'union__char__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 8)]\n",
    "                  },\n",
    "          X_training,\n",
    "          y_training) as b:\n",
    "    y_t, y_p = y_dev, b.best_estimator_.predict(X_dev)\n",
    "    print(classification_report(y_t, y_p, target_names=labelEncoder.classes_))\n",
    "    print(confusion_matrix(y_t, y_p))\n",
    "    print(\"accuracy: \", accuracy_score(y_t, y_p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "with BLA('multinomialnb_wordchar_tfidf',\n",
    "          Pipeline([('union', FeatureUnion([('char', TfidfVectorizer(analyzer='char', ngram_range=(1,8))),\n",
    "                                            ('word', TfidfVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))])),\n",
    "                    ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
    "                    ('kbest', SelectKBest()), \n",
    "                    ('mnb', MultinomialNB())]),\n",
    "          {'kbest__k': [100, 1000, 10000, 1000000, 'all'], \n",
    "                  'mnb__alpha': [0, 0.00001, 0.0001, 0.001, 0.05, 0.5, 1.0, 1.5, 2.5],\n",
    "                  'union__word__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 6)],\n",
    "                  'union__char__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 8)]\n",
    "                  },\n",
    "          X_training,\n",
    "          y_training) as b:\n",
    "    y_t, y_p = y_dev, b.best_estimator_.predict(X_dev)\n",
    "    print(classification_report(y_t, y_p, target_names=labelEncoder.classes_))\n",
    "    print(confusion_matrix(y_t, y_p))\n",
    "    print(\"accuracy: \", accuracy_score(y_t, y_p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "with BLA('sgdhinge_wordchar_tfidf',\n",
    "          Pipeline([('union', FeatureUnion([('char', TfidfVectorizer(analyzer='char', ngram_range=(1,8))),\n",
    "                                            ('word', TfidfVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))])),\n",
    "                    ('scaler', StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
    "                    ('kbest', SelectKBest()), \n",
    "                    ('sgd', SGDClassifier(shuffle=True))]),\n",
    "          {'kbest__k': [100, 1000, 10000, 1000000, 'all'], \n",
    "                  'sgd__alpha': 10.0**-np.arange(1,9),\n",
    "                  'union__word__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 6)],\n",
    "                  'union__char__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 8)]\n",
    "                  },\n",
    "          X_training,\n",
    "          y_training) as b:\n",
    "    y_t, y_p = y_dev, b.best_estimator_.predict(X_dev)\n",
    "    print(classification_report(y_t, y_p, target_names=labelEncoder.classes_))\n",
    "    print(confusion_matrix(y_t, y_p))\n",
    "    print(\"accuracy: \", accuracy_score(y_t, y_p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from file\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Deze enorme vrachtschepen zijn erg afhankelijk van hun schroef . Ze zijn soms drie verdiepingen hoog en hun bouw vereist veel kennis . Hoe doen ze dat ? Varen met een 157 . 000 ton zwaar en 397 meter lang containerschip als de Estelle M rsk , is geen eenvoudige opgave .'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-027785e0a879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           y_training) as b:\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabelEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/lamachine/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/lamachine/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/lamachine/lib/python3.6/site-packages/sklearn/feature_selection/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0minput\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/lamachine/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Deze enorme vrachtschepen zijn erg afhankelijk van hun schroef . Ze zijn soms drie verdiepingen hoog en hun bouw vereist veel kennis . Hoe doen ze dat ? Varen met een 157 . 000 ton zwaar en 397 meter lang containerschip als de Estelle M rsk , is geen eenvoudige opgave .'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "with BLA('randomforest_char_count_vect_1_8',\n",
    "          Pipeline([('union', FeatureUnion([('char', TfidfVectorizer(analyzer='char', ngram_range=(1,8))),\n",
    "                                            ('word', TfidfVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))])),\n",
    "                    ('kbest', SelectKBest()), \n",
    "                    ('rfc', RandomForestClassifier(oob_score = True))]),\n",
    "          {'kbest__k': [10,100], \n",
    "                  'rfc__max_features': [0.2, 1.0],\n",
    "                  'rfc__n_estimators': [10, 50],\n",
    "                  'rfc__min_samples_leaf': [50, 100, 250],\n",
    "                  'union__char__ngram_range': [(x,y) for x in range(1,4) for y in range(x, 6)]\n",
    "                  },\n",
    "          X_training,\n",
    "          y_training) as b:\n",
    "    y_t, y_p = y_dev, b.best_estimator_.predict(X_dev)\n",
    "    print(classification_report(y_t, y_p, target_names=labelEncoder.classes_))\n",
    "    print(confusion_matrix(y_t, y_p))\n",
    "    print(\"accuracy: \", accuracy_score(y_t, y_p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loglikelihood-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "class LLHbasedBinaryVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, count=1000):\n",
    "        self.llh_1000 = []\n",
    "        with open('data/DUT_BEL.t5m1l6.llh_t', 'r') as f:\n",
    "            for n, line in enumerate(f):\n",
    "                self.llh_1000.append(line.split(\"\\t\")[0])\n",
    "                if count != \"all\" and n >= count:\n",
    "                    break\n",
    "    \n",
    "    def llh_binary_countvectorizer(self, line):\n",
    "        values = []\n",
    "        for k in self.llh_1000:\n",
    "            values.append(1*(k in line))\n",
    "        return lil_matrix(values)\n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        result = csr_matrix((len(df),len(self.llh_1000)))\n",
    "        for r, l in enumerate(df):\n",
    "            result[r,:] = self.llh_binary_countvectorizer(l)\n",
    "        return result\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['llh_vect_100k'] = {'analyser': LLHbasedBinaryVectorizer(count=100000),\n",
    "                             'values': {'x_tr': [], 'y_tr': []},\n",
    "                            }\n",
    "for kfold in range(len(X_training)):\n",
    "    features['llh_vect_100k']['x_tr'].append(features['llh_vect_100k']['analyser'].fit_transform(X_training[kfold]))\n",
    "    features['llh_vect_100k']['y_tr'].append(features['llh_vect_100k']['analyser'].fit_transform(X_dev[kfold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding features\n",
    "No experiment these days is complete without using embeddings. It's fancier than the multilayer perceptron that we're using. [Fasttext](https://github.com/facebookresearch/fastText) seems to work quite well actually. \"Thank you Facebook.\" There, I said it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class FasttextFeatures(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, count=1000):\n",
    "\n",
    "        \n",
    "    def transform(self, df, y=None):\n",
    "        return hoi\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        \n",
    "        \n",
    "    \n",
    "    def llh_binary_countvectorizer(self, line):\n",
    "        values = []\n",
    "        for k in self.llh_1000:\n",
    "            values.append(1*(k in line))\n",
    "        return lil_matrix(values)\n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        result = csr_matrix((len(df),len(self.llh_1000)))\n",
    "        for r, l in enumerate(df):\n",
    "            result[r,:] = self.llh_binary_countvectorizer(l)\n",
    "        return result\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
