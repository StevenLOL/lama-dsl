{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains the full pipeline for our submissions to the 2018 VarDial Evaluation Campaign, in particular to the shared task for Discriminating between Dutch and Flemish in subtitles (DFS). We are participating only in the closed training track. See [the official page](http://alt.qcri.org/vardial2018/index.php?id=campaign) for more info.\n",
    "\n",
    "Running the whole stack takes a really long time, especially tuning the parameters for the models, the stacks and blends. There is a cache mechanism in place, so you don't have run it all yourself.\n",
    "\n",
    "In this notebook we run pipelines for the following features, or any combination thereof: word $n$-grams, character $n$-grams, part of speech $n$-grams, loglikelihood of $n$-grams, compression rate, language models, word embeddings. We run most of them through multiple learners, such as xgboost, random forests, linear svc, $k$ nearest neighbours, stochastic gradient descent with multiple objectives, naive bayes, nbsvm, and others. Desperate times call for desperate measures. That's why we also blend, stack, ensemble, #insertbuzzword. Especially if different learners achieve a decent score, but their results have little correlation, we expect a lot of combining the models. This is also the way to win Kaggle competitions, so yes, surely one can win this shared task this way as well. Right? (right?)\n",
    "\n",
    "There's not much background literature involved. I mean, the reference in the [literature list](https://github.com/naiaden/lama-dsl/blob/master/literature.md) don't seem to be that surprising. It also appears to be an intrinsically hard task. As a human. I think that there's also a very low human annotater agreement if one were to test this. This would then suggest that the performance ceiling is very low (I suspect around 75%, or even less). On development data we can reach around 70% accuracy (this is not the final number), so I think we're doing okayist. But I am also absolutely clueless of the competition. They will probably outwit me in imaginary ways. That'd be nice.\n",
    "\n",
    "So let's get this notebook running. The first couple of page scrolls are filled with the boring stuff. After that is the less boring, but still boring stuff. It's the actual learning at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ucto\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can enter the parts that you want to run. The identifiers are the run names, and you can find them further\n",
    "in the notebook. Use \"all\" to run all of them; this option overrules all other run names. Also note that it takes a\n",
    "seriously large amount of time to run them all.\n",
    "\n",
    "Most of the times we don't run the experiments from the notebook, but from the console, so we're doing a little testing and flagging here to make sure we show the proper output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "_run = set([])\n",
    "_use_subset = False\n",
    "_show_graphics = True\n",
    "\n",
    "import sys\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    # running in console\n",
    "    _show_graphics = False\n",
    "    from tqdm import tqdm as tqdm, trange as tnrange\n",
    "    \n",
    "    for v in sys.argv:\n",
    "        if v.startswith(\"r:\"):\n",
    "            _run.add(v[2:])\n",
    "        elif v == \"o:subset\":\n",
    "            _use_subset = True\n",
    "else:\n",
    "    # running in notebook\n",
    "    from tqdm import tqdm_notebook as tqdm, tnrange as tnrange\n",
    "    \n",
    "    _run.add(\"all\")\n",
    "    \n",
    "    _use_subset = True\n",
    "    pass\n",
    "\n",
    "def do_run(name):\n",
    "    return name in _run or \"all\" in _run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not going to do that much with confusion matrices, but they are a helpful tool in determining the true and false positives, and true and false negatives. We only/all want true positives. At least I do. Wikipedia says sensitivity and specificity. But that reads like a Jane Austen novel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAEmCAYAAAAJAaljAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XucXdP9//HXeyYhISE0tMQlRahLv4IUpdpUq0Vd2uKLIqWI+lVL0X5L1a33L99eVFtNixCt0qJVtOpb1aKkkkhU3Cl1CUmESAjN5fP7Y6/5OsbMOXsm58xZk/N+euyHc/beZ+3PPpP5zFpr77W2IgIzM6utrdkBmJn1F06YZmYlOWGamZXkhGlmVpITpplZSU6YZmYlOWH2I5IGS/qdpPmSfiXpEEl/bHZcPdH5HJajnH537t2RtIukB5sdh9Um34fZGJIeB9YF1o2IuRXr7wZGA2+PiMd7WOZhwGeBnSJiyXLGNxF4KiJOW55yenHcup1DfyApgFER8UizY7Hl5xpmY/0TOLjjjaR3AqssR3kbAg+VSTSSBizHcRqp9Dm0gox/TtaViPDSgAV4HDgNuKti3bnAl4EARgLvAp4D2iv2+Tgwo4vyzgL+DSwGFgJHAocDt1XsE8BngIcpkrWA7wKzgZeAfwBbAeNTOf9OZf2um3PYErgJmJfiPDWtXxn4HvBMWr4HrJy2jQWeAk5Kx50FHFHlHM4ELqs45sh0HgPS+8OBx4AF6ZwOqVhfee47AXcB89P/d6rYdgvwVeD2VM4fgeHdnHNH/F+siP+jwJ7AQ+m7OLVi/+2BO4AX077nAyulbX9N5/JyOt8DK8r/L+BZYFLHuvSZjdMxtk3v1wXmAGOb/W/aSzhhNuyLLRLmB4EHgc2B9vSLsmH6JRqZ9rsP2KPic9cAJ3VTZufk0jlpREpwawKDgQ8DU4FhFMlzc2CdtO9E4GtV4h+aEsBJwKD0foe07WzgTmBtYC3gb8BX07axwJK0z8CUaF4B1ujmHDq/H5nOYwCwKkWi3yxtWwfYsvO5p/N9ATgsfe7g9P4tafstwKPApul7uQX4Vjfn3RH/6Sn+o1PC+kX6DrYEFlF0qQBsB+yYjjsSuB84odPPZJMuyv82xR+ewVQkzLTP0enfxSrAjcC5zf737KVY3CRvvEnAOGA3il+mpzttvwQ4FEDSmhRJ7hfLcbxvRsS8iFhEUZMbCryDor/6/oiYVbKcvYBnI+J/IuLViFgQEZPTtkOAsyNidkTMoag5Hlbx2cVp++KIuIGidrVZL89nGbCVpMERMSsiZnaxz0eAhyNiUkQsiYjLgQeAvSv2uTgiHkrfy5UU/cjdWQx8PSIWA78EhgPfT9/BTIpktjVAREyNiDvTcR8HfgK8r8Q5nRERr6V43iAifgo8Akym+CPx5RrlWR9xwmy8ScAnKGpEl3ax/TJgb0mrAv8J3NqDpNaVJzteRMTNFE3EHwKzJU2QtFrJctanqJV1ZV3giYr3T6R1HZ6PN/ZRvgIMKXnc/xMRL1M0Yz8NzJJ0vaR3lIinI6YRFe+f7UE8z0fE0vS6I6E9V7F9UcfnJW0q6TpJz0p6CfgGRYKtZk5EvFpjn59SdJ/8ICJeq7Gv9REnzAaLiCco+t72BK7uYvvTFH1gH6eopU1a3kN2Kv+8iNgO2IKiSfqFrvbrwpPARt1se4aia6HDBmldb7zMGy+Eva1yY0TcGBG7UdS0HqBIJLXi6Yipc22+EX5MEdeoiFgNOJWi+6Oaqt+9pCEU/cIXAmemlodlwAmzbxwJ7JpqTF25lOIiwzvpIqn2lqR3SdpB0kCKxPQqRXMQihpTdwkR4DpgHUknSFpZ0lBJO6RtlwOnSVpL0nCK/r7LehnmdOC9kjaQtDpwSkX8b5W0b6p9v0bRtF/WRRk3AJtK+oSkAZIOpPgDcV0vY+qJoRT9rAtT7ffYTttrfc9d+T4wJSKOAq4HLljuKK0unDD7QEQ8GhFTquxyDUUN6ZqIeKWOh16Nokb2AkUT9XngnLTtQmALSS9K+k0XMS+g6Hfdm6I5+zDw/rT5a8AU4B6KK+/T0roei4ibgCtSWVN5Y5JrA06kqEHOo+gb7JyQiIjnKfpcT0rn+EVgr6i4/7WBTqbocllA8V1f0Wn7mcAl6Xv+z1qFSdoX2J3Xz/NEYFtJh9QtYus137ieCUmPAsdExP82OxYz65prmBmQtB9Fv9bNzY7FzLrnhNlkkm6huHDwmYjoqn/OzHpJUrukuyW9qT879c1fIekRSZMljaxVnodlNVlEjG12DGYrsOMp7n/u6na6I4EXImITSQdRDCY4sFphrmGa2QpJ0noUgxp+1s0u+1IMHAH4NfABSVVvCVshapjDhw+PDTcc2ewwrBdeXLS42SFYLz12/z1zI2KtepXXvtqGEUveNPCpS7FozkyK2+Q6TIiICZ12+x7FHRNDuylmBGmgR0QskTQfeAvQ7d0VK0TC3HDDkdw+udpdO5ar6+7t7f3u1mwHbDOi8+iq5RJLFrHyZjXvvALg1ek/fDUixnS3XdJewOyImCppbJ1CdJPczHIhUFu5pbadgX3SvLS/BHaV1HlwxdMUQ4A7ptlbneI+3m45YZpZHgS0tZdbaoiIUyJivYgYCRwE3BwRh3ba7Vrgk+n1/mmfqjemrxBNcjNbQVS/5lKH4nU2xbDTaylGu02S9AjFSLKDan3eCdPMMqGyze0eiYhbKOZAJSJOr1j/KnBAT8pywjSzfDS4hrm8nDDNLA+iITXMenLCNLNMyDVMM7PSXMM0MytDpW4ZaiYnTDPLg3CT3MysNDfJzczKaMx9mPXkhGlm+Whzk9zMrDbfh2lmVpavkpuZleer5GZmJblJbmZWgjw00sysPNcwzcxKcg3TzKwM37huZlZOxzN9MuaEaWaZcA3TzKw892GamZXkGqaZWUmuYZqZlSD3YZqZlaY2J0wzs5qKJ1S4SW5mVpvSkjEnTDPLhFzDNDMrK/eEmXcPq5m1FEmllhLlDJL0d0kzJM2UdFYX+xwuaY6k6Wk5qla5rmGaWR4Eqt9D0F4Ddo2IhZIGArdJ+n1E3Nlpvysi4riyhTphmlkWVMc+zIgIYGF6OzAtsbzlukluZtnoQZN8uKQpFcv4LspqlzQdmA3cFBGTuzjkfpLukfRrSevXis81TDPLRg9qmHMjYky1HSJiKTBa0jDgGklbRcS9Fbv8Drg8Il6TdAxwCbBrtTJdwzSzbNTrok+liHgR+DOwe6f1z0fEa+ntz4DtapXlhGlmeVAPllpFSWulmiWSBgO7AQ902medirf7APfXKtdNcjPLRh3vw1wHuERSO0XF8MqIuE7S2cCUiLgW+JykfYAlwDzg8FqFOmGaWRaEaKvT5BsRcQ+wTRfrT694fQpwSk/KdcI0s3zkPdDHCdPMMqH8h0Y6YZpZNpwwzcxKcsI0MyuhnkMjG8UJ08zyUN/JNxrCCTNjxxz1KX5/w3WstfbaTJ1+b+0PWBbmPvs053/leF58fi6S+OB+h/CRT9ScOczIv0nukT4ZO+yTh/Pb6/7Q7DCsh9rbBzDuxDP43tW38I1Lf8eNV0zkyUcfanZY/UIjhkbWkxNmxt6zy3tZc801mx2G9dAaa72VjTZ/JwCDVx3CiLePYt6cZ5scVT9Rp6GRjeImuVkDzX7mSf754L2M2upNg06sC26SA5KWpingZ0iaJmmntH6kpEUVU8RPlzQubXtc0vC+iM+sERa98jLnnnw0R5x8FqsMGdrscLJXtjnezKTaVzXMRRExGkDSh4FvAu9L2x7t2Ga2oliyeDH/c/LR7LLHx9jhA3s2O5x+I/caZjOa5KsBLzThuGZ9IiL48VknMeLtm7D3Ycc0O5x+Jffbivrqos/g1Nx+gGKizq9WbNu4U5N8lzIFShrfMT39nLlzGhJ0s4079GDG7vJuHnrwQTYeuR4TL7qw2SFZCQ9Mv4u/Xn8V9971N04+cDdOPnA3pt36p2aH1S+4SV6obJK/G7hU0lZpW6+a5BExAZgAsN12Y5b74UY5uvSyy5sdgvXC5ttsz6/ufrrZYfQ/nnzjzSLijnQxZ62+PraZ5UtA5vmy7xOmpHcA7cDzwCp9fXwzy5XHkncYnB53CcUfkk9GxNL05WxcsQ3goog4L72+R9Ky9PrKiDixj+I1sybIPF/2TcKMiPZu1j8ODO5m28gGhmRmuRG0ZX6V3CN9zCwLwgnTzKw0N8nNzEryRR8zszLkGqaZWSnFfZh5Z0wnTDPLhHzRx8ysLNcwzczKcB+mmVk5/aEP08/0MbNsSOWW2uVokKS/p6c8zJR0Vhf7rCzpCkmPSJosaWStcp0wzSwbdZwP8zVg14jYGhgN7C5px077HAm8EBGbAN8Fvl2rUCdMM8tGvWqYUViY3g5MS+d5c/cFLkmvfw18QDWysROmmWVBafKNMgswvOOJC2kZ/+by1J5mQpsN3BQRkzvtMgJ4EiAilgDzgbdUi9EXfcwsEz2aD3NuRIyptkNELAVGSxoGXCNpq4i4d3kidA3TzLJRryZ5pYh4EfgzsHunTU8D6xfH1QBgdYqJzbvlhGlm2ajXRR9Ja6WaJZIGA7sBD3Ta7Vrgk+n1/sDNEVH1+WBukptZHup74/o6wCWS2ikqhldGxHWSzgamRMS1wIXAJEmPAPOAg2oV6oRpZlmo543rEXEPsE0X60+veP0qcEBPynXCNLNsePINM7OSch8a6YRpZnnw5BtmZuXIzyU3Mysv83zphGlm+WjLPGM6YZpZNjLPl06YZpYHCdr7621Fklar9sGIeKn+4ZhZK+vPF31mUswfV3kGHe8D2KCBcZlZC8o8X3afMCNi/b4MxMxamyhuLcpZqdmKJB0k6dT0ej1J2zU2LDNrRW0qtzQtvlo7SDofeD9wWFr1CnBBI4MysxZUcmq3ZvZzlrlKvlNEbCvpboCImCdppQbHZWYtRvTjq+QVFktqIz1ASNJbgGUNjcrMWlLuF33K9GH+ELgKWCs92/c2SjyO0sysp/p9kzwiLpU0FfhgWnXA8j5IyMyss948r6evlR3p0w4spmiW+zlAZtYQuY8lL3OV/MvA5cC6wHrALySd0ujAzKz1qOTSLGVqmOOAbSLiFQBJXwfuBr7ZyMDMrLWsKFfJZ3Xab0BaZ2ZWP02+oFNGtck3vkvRZzkPmCnpxvT+Q8BdfROembWSzPNl1Rpmx5XwmcD1FevvbFw4ZtbK+m0NMyIu7MtAzKy1ieaOEy+jZh+mpI2BrwNbAIM61kfEpg2My8xaUO41zDL3VE4ELqb4A7AHcCVwRQNjMrMWlfttRWUS5ioRcSNARDwaEadRJE4zs7rpeERFmaVZytxW9FqafONRSZ8GngaGNjYsM2tFK0KT/PPAqsDngJ2Bo4FPNTIoM2tNHePJay21y9H6kv4s6T5JMyUd38U+YyXNlzQ9LafXKrfM5BuT08sFvD6JsJlZXQnVcyz5EuCkiJgmaSgwVdJNEXFfp/1ujYi9yhZa7cb1a0hzYHYlIj5e9iBmZjXVcbaiiJhFGpEYEQsk3Q+MADonzB6pVsM8f3kK7ksPPreAsef+pdlhWC/MuOJXzQ7BMtKDPszhkqZUvJ8QERO6KXMksA0wuYvN75Y0A3gGODkiZlY7aLUb1/9UK2Izs3oR0F4+Yc6NiDE1y5SGUEyAfkJEvNRp8zRgw4hYKGlP4DfAqGrleW5LM8tGPZ8aKWkgRbL8eURc3Xl7RLwUEQvT6xuAgZKGVyuz7ATCZmYNV69bLFW07S8E7o+I73Szz9uA5yIiJG1PUYF8vlq5pROmpJUj4rUexGxmVlpxy1DdrpLvTHFXzz8kTU/rTgU2AIiIC4D9gWMlLQEWAQdFRLcXuqHcWPLtKTL16sAGkrYGjoqIz/b2TMzMulKvGmZE3EaNUZQRcT49vLhdpg/zPGAvUlU1ImYA7+/JQczMyqjXjeuNUqZJ3hYRT3SqKi9tUDxm1qKK6d3yHhpZJmE+mZrlIakd+CzwUGPDMrNW1J53viyVMI+laJZvADwH/G9aZ2ZWN1Jdh0Y2RJmx5LOBg/ogFjNrcZnny1JXyX9KF2PKI2J8QyIys5bV7x9RQdEE7zAI+BjwZGPCMbNWtUJc9ImINzyOQtIk4LaGRWRmLSvzfNmroZFvB95a70DMrMWpR5NvNEWZPswXeL0Psw2YB3ypkUGZWevp94/ZTQPYt6Z4jg/AslpjLc3Meiv3hFl1aGRKjjdExNK0OFmaWcNIKrU0S5mx5NMlbdPwSMyspXU0yes1H2YjVHumz4CIWEIxtftdkh4FXqY4r4iIbfsoRjNrBU2eWKOMan2Yfwe2Bfbpo1jMrIUJGJB5J2a1hCmAiHi0j2IxsxbXn2uYa0k6sbuN3U37bmbWO6Kt+py/TVctYbYDQ6gxa7GZWT2I/l3DnBURZ/dZJGbW2pp8BbyMmn2YZmZ9pT9PvvGBPovCzFpev26SR8S8vgzEzKw98zZ5b2YrMjOrO1Fu6GEzOWGaWR5EU8eJl+GEaWbZyDtdOmGaWSZWiEdUmJn1lbzTpROmmWVDtGV+lTz3i1Jm1iI6rpKXWWqWJa0v6c+S7pM0U9LxXewjSedJekTSPZJqTlnpGqaZZaOOV8mXACdFxDRJQ4Gpkm6KiPsq9tkDGJWWHYAfp/93yzVMM8uGSi61RMSsiJiWXi8A7gdGdNptX+DSKNwJDJO0TrVyXcM0szz07D7M4ZKmVLyfEBETuixWGknx5IjJnTaNAJ6seP9UWjeru4M6YZpZFno40mduRIypWaY0BLgKOCEiXup1cIkTppllo54jfSQNpEiWP4+Iq7vY5Wlg/Yr36/H6I8W75D5MM8tGvZ4aqSLzXgjcX+XpENcC49LV8h2B+RHRbXMcXMM0s0wUTfK61TB3Bg4D/iFpelp3KrABQERcANwA7Ak8ArwCHFGrUCdMM8tGvVrkEXEbNS6oR0QAn+lJuU6YZpYJocwHRzphmlk2Mp97wwnTzPJQ5z7MhnDCNLM8CNoyv2/HCdPMsuE+TOuVldrFjw8ZzUoD2miXuPnBOfzstieaHZb1QFubuP3nX+SZ2fPZ7/gLmh1O9ooJhJsdRXVOmJn699LguMtnsGjxMtrbxIRDR3PHY/OY+cyCZodmJR33iffz4D+fY+iqg5odSr+Rew0z8x6D1rZo8TIABrSJAW2CaHJAVtqItYex+3u25OJr/tbsUPoVqdzSLK5hZqxNMPHw7VhvjcFcNe1pZs5y7bK/OOcL+/Hl7/+GIau4dtkTLVvDlLRU0vQ02/EMSSdJakvbDpd0fqf9b5E0RtLk9Ll/SZqTXk9PUzS1lGUB4y6eyj4/vIMt1lmNjYav0uyQrIQ9dtmK2fMWcPf9T9be2f6PEO0qtzRLI2uYiyJiNICktYFfAKsBZ1T7UETskD5zODAmIo5rYIz9wsLXljL1Xy+y40Zr8tjcV5odjtXw7tEbsdf73snu79mSlVcayGqrDuKir43jU6dd2uzQ8tbk5nYZfdIkj4jZksYDd0k6sy+O2d8NGzyQJcuWsfC1paw8oI3tR67BpDv/1eywrITTf3Atp//gWgB22W4UJ4z7gJNlSZnny77rw4yIxyS1A2vXo7yUgMcDrDTsrfUoMivDh6zEV/bajHYJSfzpgTnc/ui8Zodl1jB+Lnn3urveW/o6cJqOfgLAkPU2W+GuHz8y52U+efG0Zodhy+nWqQ9z69SHmx1Gv5F3uuzDhClpI2ApMBt4Hlij0y5rAnP7Kh4zy1DmGbNP7sOUtBZwAXB+moPuLmBnSW9L28cAK/PGBxKZWYtRyf+apZE1zMFppuOBFM8IngR8ByAinksPVr8h3Wq0EDg4IpY1MB4zy1zLDo2MiPYa238L/LbK9onAxPpGZWZZa9WEaWbWEyL/kT5OmGaWB9+4bmZWXub50gnTzDKSecZ0wjSzTMgjfczMyhDZVzCdMM0sI5lnTCdMM8uGbysyMysp8y5MJ0wzy0fm+dIPQTOzTKgHS62ipIskzZZ0bzfbx0qaX/EInNPLhOgapplloc4TCE8EzgeqTXV/a0Ts1ZNCXcM0s2zUqYJJRPwVqPsjCpwwzSwf5TPmcElTKpbxvTjau9MTbX8vacsyH3CT3Myy0YPbiuZGxJjlONQ0YMOIWChpT+A3wKhaH3IN08yyIZVblldEvBQRC9PrG4CBkobX+pwTppllo159mDWPI71NKlKvpO0pcuHztT7nJrmZZUGA6nSVXNLlwFiKvs6ngDMoHpdDRFwA7A8cK2kJsAg4KD1vrConTDPLQx0nEI6Ig2tsP5/itqMeccI0s2zkPtLHCdPM8pF5xnTCNLNMNPeZ42U4YZpZNjxbkZlZCcVV8mZHUZ0Tppllw01yM7OSXMM0Mysp83zphGlmmajjjeuN4oRpZhnJO2M6YZpZFnyV3MysB9qcMM3MyvFtRWZmZeWdL50wzSwfmedLJ0wzy0O9Hj/RSE6YZpYN92GamZXkGqaZWUlOmGZmpXgCYTOzUvrDSB8/l9zMrCTXMM0sG7nXMJ0wzSwb7sM0MytB8uQbZmblOWGamZXjJrmZWUm5X/TxbUVmlg2VXGqWI10kabake7vZLknnSXpE0j2Sti0TnxOmmeWjXhkTJgK7V9m+BzAqLeOBH5cp1AnTzLIgoE0qtdQSEX8F5lXZZV/g0ijcCQyTtE6tcleIPsyXn35o7uRTxj7R7DgaaDgwt9lBWI+t6D+3DetZ2LRpU28cPFDDS+4+SNKUivcTImJCDw43Aniy4v1Tad2sah9aIRJmRKzV7BgaSdKUiBjT7DisZ/xz65mIqNaEzoKb5GbWip4G1q94v15aV5UTppm1omuBcelq+Y7A/Iio2hyHFaRJ3gJ60jdj+fDPrUkkXQ6MBYZLego4AxgIEBEXADcAewKPAK8AR5QqNyIaEa+Z2QrHTXIzs5KcMM3MSnLCNOsDknaQtH7tPS1nTphmDSbpw8DlFDeyWz/mhJk510r6t5QsLwaOjYi7JfnOlH7MCTNjklYFbpF0QrNjsZ5LyfJ8YAqwuaTVImKJJP/e9VP+wWVK0ubAv4GDgGMkHVuxra3idXsTwrMaJP0HRbI8CjgdGAmcKGlIRCxz0uyf/EPLkKQ9KZpxG0XEXcBhFL9s/w8gIpal/Q4CjpNyn3a1tUjaGhgEfCwi/gLMBK4HVgdOdtLsv/wDy0xqxn0FOCMiHpQ0LCKmAAdSkTQlHQWcA/wxPPogNx8Gvk0xZdhKEbEY+BOvJ83PSxra8YfP+g+P9MlIasZNBz4YETdL2hj4CXByREyXNAa4DHgA2BLYPyJmNC9i646kz1FMUvt1YHJELE41yrEU3SyPAv/tP3b9ixNmRiQNAS4FZgPfAi4E/hAR50hqS8240cAPKa663tPEcK1C6nNWRNxXse7zwG7AVyPijrSuDdgFeCAinmtKsNZrTpgZkDQcWBYR8yStBFwEHAycEBE/qEiW76XoD5sfEUuaGbO9TtJQ4ESK6cLOjYgHKradCHwU+HhErMiTCbcE92E2WbrAcwNwgaSvR8S/gU8DvwR2guIij6QjKGqdg5ws8xIRC4BfU8zgfZykLSq2fQd4CPhck8KzOnLCbCJJuwOnUvRzfQPYQNIqEbGQYrqpJZImSToUOBIYHxE1Jzm1viFplKSdJL0PeBy4gOKRFMdWJk3gPuD5JoRodeYmeZNIWpPil2u/iLhG0vbAb4FrgPaIOCY1z68C3g9sX9k/Zs0l6SPAV4EngKEUTx/cE3gVOATYBJgErAmcDIyLiPubE63VixNmE6Vfuq8BhwPnAn8DfkbRvPtnRByURvusHhHPNC1Qe4PUMjgT+K90nyWSzqT4Oe4BPEbRQtgbmA98MyL+0YxYrb6cMJss/fLdAJwaEd9K64ZQ1DYP9IWCvFS0DPaJiOskDYqIV9O2syhql9tFxPzUQoh0H6atANyH2WQR8QeKG52PkDQsrT4AGAy81rTArEsRMY+i5vhNSW+JiFclrZy2nUFx4WdUev9vJ8sVi2dOyUBE3JQm2LhN0o8obmwen66+WmYi4npJy4C/SxoTES9IGpiS40sU/Zi2AnLCzERE/D5NpHE1sE1EzGx2TNa99PM6DphSkTTHAW+jGHhgKyD3YWYm3Vb0SrPjsHIk7QH8N/AjiklSxkfEvc2NyhrFCdNsOUnaC7cMWoITplkduGXQGpwwzcxK8m1FZmYlOWGamZXkhGlmVpITpplZSU6YLUbSUknTJd0r6VeSVlmOssZKui693kfSl6rsO6zjeUQ9PMaZkk4uu77TPhMl7d+DY42U5HsorVtOmK1nUUSMjoitKB7j++nKjSr0+N9FRFzbMXlIN4YBPU6YZjlxwmxttwKbpJrVg5IuBe4F1pf0IUl3SJqWaqJDoJhdSdIDkqYBH+8oSNLhks5Pr98q6RpJM9KyE8Vs8Run2u05ab8vSLpL0j1ppp+Osr4s6SFJtwGb1ToJSUencmZIuqpTrfmDkqak8vZK+7dLOqfi2Mcs7xdprcEJs0VJGkAxd2PHPI2jgB9FxJbAy8BpFE+v3BaYQvGI30HATylm69mOYtx0V84D/hIRWwPbUjyH6EvAo6l2+wVJH0rH3B4YDWwn6b2StqOYfGQ0xYS87ypxOldHxLvS8e6nmJ2+w8h0jI9QPAZkUNo+PyLelco/WtLbSxzHWpwn32g9gyVNT69vpXgy5brAExFxZ1q/I7AFcLskgJWAO4B3UExs/DCApMuA8V0cY1dgHEBELAXmS1qj0z4fSsvd6f0QigQ6FLimY9SMpGtLnNNWkr5G0ewfAtxYse3K9PzvhyU9ls7hQ8B/VPRvrp6O/VCJY1kLc8JsPYsiYnTlipQUX65cBdwUEQd32u8Nn1tOopiJ/CedjnFCL8qaCHw0ImZIOpzi2d8dOg9li3Tsz0ZEZWJF0sheHNtaiJvk1pU7gZ0lbQIgaVVJmwIPACMlbZz2O7ibz/8JODZ9tl3S6sACitpjhxuBT1X0jY6QtDbwV+CjkgareHzt3iXiHQrMkjSQYsbzSgdIaksxbwQ8mI59bNofSZumR4GYVeUapr1JRMxJNbXLO2YTB06LiIckjQeul/QKRZN+aBdFHA/uf9f8AAAAfklEQVRMkHQksBQ4NiLukHR7um3n96kfc3PgjlTDXQgcGhHTJF0BzKCYV/KuEiF/BZgMzEn/r4zpX8DfgdWAT6cZ0n9G0bc5TcXB51A8O9ysKk++YWZWkpvkZmYlOWGamZXkhGlmVpITpplZSU6YZmYlOWGamZXkhGlmVtL/Bw99WavRG6CHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2e24136a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "                      \n",
    "cm = confusion_matrix(['BEL', 'BEL', 'DUT', 'DUT', 'BEL', 'DUT', 'DUT', 'DUT', 'DUT', 'DUT'],  # golden truth\n",
    "                      ['BEL', 'DUT', 'DUT', 'BEL', 'DUT', 'DUT', 'BEL', 'BEL', 'DUT', 'DUT'])  # our predictions\n",
    "    \n",
    "if _show_graphics:\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes=[\"BEL\", \"DUT\"], title=\"My first confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for this example, we assume that in this binary classification task we have to predict whether it's a Flemish subtitle or not. That means that Flemish is the positive class, and Netherlandic the negative class. (I obviously don't agree, but since I'm also connected to the KU Leuven, I can live with this.) Then if we properly classified the Flemish subtitle as a Flemish subtitle, it's a true positive. In this case we found 1. On the other hand we can also correctly guess that a negative example is indeed a Netherlandic subtitle. That's a true negative, and we've found 4 of them. The other two classes are confusion, be it a Flemish subtitle confused for a Netherlandic subtitle (2 out of 10 cases; false positives), or Netherlandic subtitles confused as Flemish subtitles (3 out of 10 cases; false negatives). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keep track of the runs, especially the best run of a series, its output and its parameters. To this end we have a little structure here to keep them all in one place. You have to call the functions in the order as they are defined. First you register the run with a unique name (or rather, all runs with the same name have their results merged), then you can update its statistics, and at any point you can ask for a summary of the run. One of the feats is that it will show one of those fancy confusion matrices for you. The last function is summarise_all. This one presents you with a nice goodnight story. Yes. It'll make you yawn and fall asleep. Impressed though, you will fall asleep impressed by the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_run_stats = {}\n",
    "\n",
    "import os.path\n",
    "def register_run(name, description, params):\n",
    "    if name not in _run_stats:\n",
    "        # if can be loaded from file\n",
    "        if os.path.exists('cache/' + name + '.json'):\n",
    "            with open('cache/' + name + '.json', 'r') as f:\n",
    "                run_object = json.load(f)\n",
    "                _run_stats[name] = {}\n",
    "                _run_stats[name]['description'] = run_object['description']\n",
    "#                 _run_stats[name]['params'] = run_object['params']\n",
    "                _run_stats[name]['best'] = run_object['best']\n",
    "                _run_stats[name]['best_predictions'] = np.array(run_object['best_predictions'])\n",
    "#                 print(np.matrix(run_object['best_predictions']))\n",
    "                _run_stats[name]['orig_predictions'] = np.array(run_object['orig_predictions'])\n",
    "                _run_stats[name]['history'] = run_object['history']\n",
    "        else:\n",
    "            _run_stats[name] = {}\n",
    "            _run_stats[name]['description'] = description\n",
    "#             _run_stats[name]['params'] = {}\n",
    "#             for param in params:\n",
    "#                 _run_stats[name]['params'][param] = ''\n",
    "\n",
    "            _run_stats[name]['best'] = 0\n",
    "            _run_stats[name]['best_predictions'] = []\n",
    "            _run_stats[name]['orig_predictions'] = []\n",
    "            _run_stats[name]['history'] = []\n",
    "\n",
    "def update_stats(name, y_test, y_pred, params):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    _run_stats[name]['history'].append(accuracy)\n",
    "    if accuracy > _run_stats[name]['best']:\n",
    "        _run_stats[name]['best'] = accuracy\n",
    "#         for param in params:\n",
    "#             _run_stats[name]['params'][param] = params[param]\n",
    "        _run_stats[name]['best_predictions'] = y_pred\n",
    "        _run_stats[name]['orig_predictions'] = y_test\n",
    "        \n",
    "        with open(\"cache/\" + name + \".json\", 'w') as f:\n",
    "            json.dump({'best_predictions': _run_stats[name]['best_predictions'].tolist(),\n",
    "                       'description': _run_stats[name]['description'],\n",
    "#                        'params': _run_stats[name]['params'],\n",
    "                       'history': _run_stats[name]['history'],\n",
    "                       'orig_predictions': _run_stats[name]['orig_predictions'].tolist(),\n",
    "                       'best': _run_stats[name]['best']\n",
    "                      }, f)\n",
    "#         with open('cache/' + name + '.pickle', 'w') as f:\n",
    "#             pickle.dump(_run_stats[name], f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "def summarise_run(name):\n",
    "    if name not in _run_stats:\n",
    "        print(\"Name %s is not registrered.\" % (name))\n",
    "        return\n",
    "    \n",
    "    print(\"Model:    \\n\\t%s\" % (name))\n",
    "    #print(\"Settings: \\n\\t%s\" % (_run_stats[name]['params']))\n",
    "    print(\"Accuracy: \\n\\t%s\" % (_run_stats[name]['best']))\n",
    "\n",
    "    cm = confusion_matrix(_run_stats[name]['orig_predictions'], _run_stats[name]['best_predictions'])\n",
    "    \n",
    "    if _show_graphics:\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(cm, classes=[\"BEL\", \"DUT\"], title=name)# + \" \" + str(_run_stats[name]['params']))\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(cm)       \n",
    "\n",
    "def summarise_all():\n",
    "    for name in _run_stats.keys():\n",
    "        summarise_run(name)\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(file):\n",
    "    with open(file) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the file with [ucto](https://github.com/proycon/python-ucto) and tokenise it according to its default Dutch tokenisation scheme, which is rule-based\n",
    "and definitely better than a plain whitespace tokeniser from sklearn. Afterwards we concatenate the tokens back to a \n",
    "whitespace seperated line, which can then be normally processed with sklearn's tokenisers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucto_config = \"tokconfig-nld\"\n",
    "tokeniser = ucto.Tokenizer(ucto_config, sentenceperlineinput=True, sentencedetection=False, paragraphdetection=False)\n",
    "\n",
    "def read_data(file):\n",
    "    text = {}\n",
    "    with open(file) as f:\n",
    "        for line in tqdm(f):\n",
    "            sentence, language = line.strip().split(\"\\t\")\n",
    "            tokeniser.process(sentence)\n",
    "\n",
    "            if language not in text:\n",
    "                text[language] = []\n",
    "\n",
    "            current_line = []\n",
    "            for token in tokeniser:\n",
    "                current_line.append(str(token))\n",
    "                if token.isendofsentence():\n",
    "                    #print(current_line)\n",
    "                    text[language].append(\" \".join(current_line))\n",
    "                    current_line = []\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is the first run, then we have to tokenise the text. In other cases we probably have saved a pickled version\n",
    "somewhere. If not, we will tokenise the text anyway. No worries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First the development set\n",
    "try:\n",
    "    with open('data/dev.txt.pickle', 'rb') as f:\n",
    "        _l_dev_text = pickle.load(f)\n",
    "        print(\"Done reading development set from pickle.\")\n",
    "except IOError:\n",
    "    _l_dev_text = read_data('data/dev.txt')\n",
    "    print(\"Done tokenising development set.\")\n",
    "    with open('data/dev.txt.pickle', 'wb') as f:\n",
    "        pickle.dump(_l_dev_text, f, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Done writing development set from pickle.\")\n",
    "\n",
    "print(\"development set\")\n",
    "print(\"\\t LAN\\t size \\t avg length\")\n",
    "for l in _l_dev_text.keys():\n",
    "    print(\"\\t\", l, \"\\t\", len(_l_dev_text[l]), \"\\t\", sum([len(x.split()) for x in _l_dev_text[l]])/len(_l_dev_text[l]))\n",
    "\n",
    "# And then the training set. This takes bit more time...\n",
    "try:\n",
    "    with open('data/train.txt.pickle', 'rb') as f:\n",
    "        _l_trn_text = pickle.load(f)\n",
    "        print(\"Done reading training set from pickle.\")\n",
    "except IOError:\n",
    "    _l_trn_text = read_data('data/train.txt')\n",
    "    print(\"Done tokenising training set.\")\n",
    "    with open('data/train.txt.pickle', 'wb') as f:\n",
    "        pickle.dump(_l_trn_text, f, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Done writing training set from pickle.\")\n",
    "\n",
    "print(\"training set\")\n",
    "print(\"\\t LAN\\t size \\t avg length\")\n",
    "for l in _l_trn_text.keys():\n",
    "    print(\"\\t\", l, \"\\t\", len(_l_trn_text[l]), \"\\t\", sum([len(x.split()) for x in _l_trn_text[l]])/len(_l_trn_text[l]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is as good a time as any to import some random stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the training and development material into the right shape, and make sure that we also keep track of\n",
    "the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = []\n",
    "y_training = []\n",
    "for l in _l_trn_text.keys():\n",
    "    for s in _l_trn_text[l]:\n",
    "        X_training.append(s)\n",
    "        y_training.append(l)\n",
    "X_training = np.array(X_training)\n",
    "y_training = np.array(y_training)\n",
    "\n",
    "\n",
    "X_dev = []\n",
    "y_dev = []\n",
    "for l in _l_dev_text.keys():\n",
    "    for s in _l_dev_text[l]:\n",
    "        X_dev.append(s)\n",
    "        y_dev.append(l)\n",
    "X_dev = np.array(X_dev)\n",
    "y_dev = np.array(y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the features that was promised to deliver mountains of gold, and other glory, such as the first place in whatever context is part of speech tags. We will generate them with [frog](https://github.com/proycon/python-frog). We're not really interested in the full tag, but more so in the head of the tag. That's why it's the only part we're keeping. It's slow. It's faster to generate them yourself than to ask me to mail you them but still. It's slooow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/' + 'dev' + '.POS.txt') or not os.path.exists('data/' + 'train' + '.POS.txt'):\n",
    "    import frog\n",
    "\n",
    "    frog = frog.Frog(frog.FrogOptions(parser=False))\n",
    "\n",
    "    for t in ['dev', 'train']:\n",
    "        with open('data/' + t + '.POS.txt', 'w') as out:\n",
    "            with open('data/' + t + '.txt', 'r') as f:\n",
    "                for line in f:\n",
    "                    sentence, tag = line.strip().split(\"\\t\")\n",
    "                    froggo = frog.process(sentence)\n",
    "                    postext = []\n",
    "                    for w in froggo:\n",
    "                        postext.append(w['pos'].split(\"(\")[0])\n",
    "                    out.write(\" \".join(postext) + \"\\t\" + tag + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the part of speech training material into the same form as two cells up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pos texts into X_pos_training etc.\n",
    "\n",
    "X_pos_training = []\n",
    "y_pos_training = []\n",
    "with open('data/train.POS.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        sentence, tag = line.strip().split(\"\\t\")\n",
    "        X_pos_training.append(sentence)\n",
    "        y_pos_training.append(tag)\n",
    "X_pos_training = np.array(X_pos_training)\n",
    "y_pos_training = np.array(y_pos_training)\n",
    "\n",
    "X_pos_dev = []\n",
    "y_pos_dev = []\n",
    "with open('data/dev.POS.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        sentence, tag = line.strip().split(\"\\t\")\n",
    "        X_pos_dev.append(sentence)\n",
    "        y_pos_dev.append(tag)\n",
    "X_pos_dev = np.array(X_pos_dev)\n",
    "y_pos_dev = np.array(y_pos_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes for testing whether some code words, you might want to use a subset. Use this one. Or another one. I don't\n",
    "care. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#use = random.sample(range(1, 299999), 100000)\n",
    "use = random.sample(range(1, 299999), 500)\n",
    "\n",
    "if _use_subset:   \n",
    "    X_training = X_training[use]\n",
    "    y_training = y_training[use]\n",
    "    \n",
    "    print(\"training subset\")\n",
    "    #print(\"\\t LAN\\t size \\t avg length\")\n",
    "    #for l in _l_trn_text.keys():\n",
    "    #    print(\"\\t\", l, \"\\t\", len(_l_trn_text[l]), \"\\t\", sum([len(x.split()) for x in _l_trn_text[l]])/len(_l_trn_text[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count-based features\n",
    "Okay, so let's get the feature engineering started. First we will introduce some classes that automagically register, and update the stats for the run. It's still a mess compared to only using sklearn's pipeline. But hey, we never said it was a clean fight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizerFeatures():\n",
    "    \n",
    "    def __init__(self, name, X, Y, x, y, description, classifier, features, feature_selection = None, scaler = None, min_cn = 1, max_cn = 8, min_n = 1, max_n = 6):\n",
    "        self.run_name = name\n",
    "        self.run_description = description\n",
    "        \n",
    "        self.classifier = classifier\n",
    "        self.features = features\n",
    "        self.feature_selection = feature_selection\n",
    "        self.scaler = scaler\n",
    "    \n",
    "        self.run_min_cn = min_cn\n",
    "        self.run_max_cn = max_cn\n",
    "        \n",
    "        self.run_min_n = min_n\n",
    "        self.run_max_n = max_n\n",
    "    \n",
    "        register_run(self.run_name, self.run_description, [])\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        #print(\"Classifier:\", self.classifier)\n",
    "        #print(\"Feature extraction:\", self.features)\n",
    "        #print(\"Feature selection:\", self.feature_selection)\n",
    "        #print(\"Feature scaler:\", self.scaler)\n",
    "                \n",
    "        self.pipeline = Pipeline([\n",
    "            ('features',   FeatureUnion(self.features)),\n",
    "            ('scaler',     self.scaler),\n",
    "            ('selection',  self.feature_selection),\n",
    "            ('classifier', self.classifier),\n",
    "        ])\n",
    "\n",
    "        model = self.pipeline.fit(X_training, y_training)\n",
    "        self.y_pred = model.predict(X_dev)\n",
    "\n",
    "        update_stats(self.run_name, y_dev, self.y_pred, {'min_cn': self.run_min_cn, 'max_cn': self.run_max_cn, 'min_n': self.run_min_n, 'max_n': self.run_max_n})\n",
    "        \n",
    "        return accuracy_score(y_dev, self.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "class CountVectorFeatures(VectorizerFeatures):\n",
    "    \n",
    "    def __init__(self, name, X, Y, x, y, description, classifier, feature_selection = None, scaler = None, min_cn = 1, max_cn = 8, min_n = 1, max_n = 6):\n",
    "        \n",
    "        features = [('char', CountVectorizer(analyzer='char', ngram_range=(min_cn,max_cn))),\n",
    "                    ('words', CountVectorizer(analyzer='word', ngram_range=(min_n,max_n),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))\n",
    "                   ]\n",
    "        super(CountVectorFeatures, self).__init__(name, X, Y, x, y, description, classifier, features, feature_selection, scaler, min_cn, max_cn, min_n, max_n)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "        \n",
    "class SelectCountVectorFeatures(CountVectorFeatures):\n",
    "    \n",
    "    def __init__(self, name, X, Y, x, y, description, classifier, feature_selection = None, scaler = None, min_cn = 1, max_cn = 8, min_n = 1, max_n = 6, k = 100):\n",
    "        features = [('char', CountVectorizer(analyzer='char', ngram_range=(min_cn,max_cn))),\n",
    "                    ('words', CountVectorizer(analyzer='word', ngram_range=(min_n,max_n),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))\n",
    "                   ]\n",
    "        super(SelectCountVectorFeatures, self).__init__(name, X, Y, x, y, description, classifier, feature_selection, scaler, min_cn, max_cn, min_n, max_n)\n",
    "\n",
    "        self.k = k\n",
    "        self.feature_selection = SelectKBest(chi2, k=k)\n",
    "\n",
    "##\n",
    "        \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "class TfidfVectorFeatures(VectorizerFeatures):\n",
    "    \n",
    "    def __init__(self, name, X, Y, x, y, description, classifier, feature_selection = None, scaler = None, min_cn = 1, max_cn = 8, min_n = 1, max_n = 6):\n",
    "        \n",
    "        features = [('char', TfidfVectorizer(analyzer='char', ngram_range=(min_cn,max_cn))),\n",
    "                    ('words', TfidfVectorizer(analyzer='word', ngram_range=(min_n,max_n),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))\n",
    "                   ]\n",
    "        super(TfidfVectorFeatures, self).__init__(name, X, Y, x, y, description, classifier, features, feature_selection, scaler, min_cn, max_cn, min_n, max_n)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "        \n",
    "class SelectTfidfVectorFeatures(TfidfVectorFeatures):\n",
    "    \n",
    "    def __init__(self, name, X, Y, x, y, description, classifier, feature_selection = None, scaler = None, min_cn = 1, max_cn = 8, min_n = 1, max_n = 6, k = 100):\n",
    "        features = [('char', TfidfVectorizer(analyzer='char', ngram_range=(min_cn,max_cn))),\n",
    "                    ('words', TfidfVectorizer(analyzer='word', ngram_range=(min_n,max_n),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))\n",
    "                   ]\n",
    "        super(SelectTfidfVectorFeatures, self).__init__(name, X, Y, x, y, description, classifier, feature_selection, scaler, min_cn, max_cn, min_n, max_n)\n",
    "\n",
    "        self.k = k\n",
    "        self.feature_selection = SelectKBest(chi2, k=k)\n",
    "\n",
    "##\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "class POSVectorFeatures(VectorizerFeatures):\n",
    "    \n",
    "    def __init__(self, name, X, Y, x, y, description, classifier, feature_selection = None, scaler = None, min_n = 2, max_n = 6):\n",
    "        \n",
    "        features = [('words', TfidfVectorizer(analyzer='word', use_idf=False, ngram_range=(min_n,max_n),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))\n",
    "                   ]\n",
    "        super(POSVectorFeatures, self).__init__(name, X, Y, x, y, description, classifier, features, feature_selection, scaler, min_n, max_n)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "        \n",
    "class SelectPOSVectorFeatures(POSVectorFeatures):\n",
    "    \n",
    "    def __init__(self, name, X, Y, x, y, description, classifier, feature_selection = None, scaler = None, min_n = 2, max_n = 6, k = 100):\n",
    "        features = [('words', TfidfVectorizer(analyzer='word', use_idf=False, ngram_range=(min_n,max_n),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))\n",
    "                   ]\n",
    "        super(SelectPOSVectorFeatures, self).__init__(name, X, Y, x, y, description, classifier, feature_selection, scaler, min_n, max_n)\n",
    "\n",
    "        self.k = k\n",
    "        self.feature_selection = SelectKBest(chi2, k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I borrowed the following code for a naive bayes support vector machine learner from [this Kaggle kernel](https://www.kaggle.com/eliotbarr/text-mining-with-sklearn-keras-mlp-lstm-cnn), but see [nbsvm](https://github.com/sidaw/nbsvm) for a more extensive overview, and for proper credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "from abc import ABCMeta\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn.preprocessing import normalize, binarize, LabelBinarizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "class NBSVM(six.with_metaclass(ABCMeta, BaseEstimator, ClassifierMixin)):\n",
    "\n",
    "    def __init__(self, alpha=1.0, C=1.0, max_iter=10000):\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.svm_ = [] # fuggly\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y, 'csr')\n",
    "        _, n_features = X.shape\n",
    "\n",
    "        labelbin = LabelBinarizer()\n",
    "        Y = labelbin.fit_transform(y)\n",
    "        self.classes_ = labelbin.classes_\n",
    "        if Y.shape[1] == 1:\n",
    "            Y = np.concatenate((1 - Y, Y), axis=1)\n",
    "\n",
    "        # LabelBinarizer().fit_transform() returns arrays with dtype=np.int64.\n",
    "        # so we don't have to cast X to floating point\n",
    "        Y = Y.astype(np.float64)\n",
    "\n",
    "        # Count raw events from data\n",
    "        n_effective_classes = Y.shape[1]\n",
    "        self.class_count_ = np.zeros(n_effective_classes, dtype=np.float64)\n",
    "        self.ratios_ = np.full((n_effective_classes, n_features), self.alpha,\n",
    "                                 dtype=np.float64)\n",
    "        self._compute_ratios(X, Y)\n",
    "\n",
    "        # flugglyness\n",
    "        for i in range(n_effective_classes):\n",
    "            X_i = X.multiply(self.ratios_[i])\n",
    "            svm = LinearSVC(C=self.C, max_iter=self.max_iter)\n",
    "            Y_i = Y[:,i]\n",
    "            svm.fit(X_i, Y_i)\n",
    "            self.svm_.append(svm) \n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_effective_classes = self.class_count_.shape[0]\n",
    "        n_examples = X.shape[0]\n",
    "\n",
    "        D = np.zeros((n_effective_classes, n_examples))\n",
    "\n",
    "        for i in range(n_effective_classes):\n",
    "            X_i = X.multiply(self.ratios_[i])\n",
    "            D[i] = self.svm_[i].decision_function(X_i)\n",
    "        \n",
    "        return self.classes_[np.argmax(D, axis=0)]\n",
    "        \n",
    "    def _compute_ratios(self, X, Y):\n",
    "        \"\"\"Count feature occurrences and compute ratios.\"\"\"\n",
    "        if np.any((X.data if issparse(X) else X) < 0):\n",
    "            raise ValueError(\"Input X must be non-negative\")\n",
    "\n",
    "        self.ratios_ += safe_sparse_dot(Y.T, X)  # ratio + feature_occurrance_c\n",
    "        normalize(self.ratios_, norm='l1', axis=1, copy=False)\n",
    "        row_calc = lambda r: np.log(np.divide(r, (1 - r)))\n",
    "        self.ratios_ = np.apply_along_axis(row_calc, axis=1, arr=self.ratios_)\n",
    "        check_array(self.ratios_)\n",
    "        self.ratios_ = sparse.csr_matrix(self.ratios_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we're finally doing with all the initial yabba yabba and the super boring stuff, here's some learning and results. In the code above each run are some results from the search for the best parameters. In the end for the final pipeline I'll just pick the best one and rock with that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# old info\n",
    "# 100 0.658\n",
    "# 1000 0.658\n",
    "# 10000 0.648\n",
    "# 100000 0.656\n",
    "# Model:    \n",
    "#         rfo_sc\n",
    "# Settings: \n",
    "#         {'max_n': 6, 'max_cn': 8, 'min_cn': 1, 'min_n': 1}\n",
    "# Accuracy: \n",
    "#         0.658\n",
    "# [[190  60]\n",
    "#  [111 139]]\n",
    "if do_run(\"rfo_sc\"):\n",
    "    for k in [1000, 10000]:\n",
    "        for max_features in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "            for n_estimators in [10, 50, 100, 150, 200, 250]:\n",
    "                for min_sample_leaf in [10, 25, 50, 75, 100, 250]:\n",
    "                    for n_jobs in [30]:\n",
    "                        print(max_features, n_estimators, min_sample_leaf, n_jobs)\n",
    "                        model = SelectCountVectorFeatures(\"rfo_sc\", X_training, y_training, X_dev, y_dev, \n",
    "                                                          \"c&w n-grams, counts, random forests\",\n",
    "                                                          RandomForestClassifier(max_features=max_features,\n",
    "                                                                                n_estimators=n_estimators,\n",
    "                                                                                min_samples_leaf=min_sample_leaf,\n",
    "                                                                                n_jobs=n_jobs,\n",
    "                                                                                random_state=571989,\n",
    "                                                                                oob_score=True), \n",
    "                                                          k=k)\n",
    "                        model_acc = model.run()\n",
    "                        print(k, model_acc)  \n",
    "summarise_run(\"rfo_sc\")\n",
    "\n",
    "# FINAL\n",
    "# 100 0 0.572\n",
    "# 100 0.001 0.572\n",
    "# 100 0.05 0.572\n",
    "# 100 0.5 0.572\n",
    "# 100 1.0 0.572\n",
    "# 100 1.5 0.572\n",
    "# 100 2.5 0.572\n",
    "# 1000 0 0.558\n",
    "# 1000 0.001 0.558\n",
    "# 1000 0.05 0.558\n",
    "# 1000 0.5 0.558\n",
    "# 1000 1.0 0.558\n",
    "# 1000 1.5 0.558\n",
    "# 1000 2.5 0.558\n",
    "# 10000 0 0.572\n",
    "# 10000 0.001 0.572\n",
    "# 10000 0.05 0.572\n",
    "# 10000 0.5 0.572\n",
    "# 10000 1.0 0.572\n",
    "# 10000 1.5 0.572\n",
    "# 10000 2.5 0.572\n",
    "# 100000 0 0.588\n",
    "# 100000 0.001 0.59\n",
    "# 100000 0.05 0.586\n",
    "# 100000 0.5 0.586\n",
    "# 100000 1.0 0.586\n",
    "# 100000 1.5 0.584\n",
    "# 100000 2.5 0.584\n",
    "# Model:    \n",
    "#         mnb_sc\n",
    "# Accuracy: \n",
    "#         0.59\n",
    "# [[155  95]\n",
    "#  [110 140]]\n",
    "if do_run(\"mnb_sc\"):\n",
    "    for k in [100000]:\n",
    "        for alpha in [0.001]:\n",
    "            model = SelectCountVectorFeatures(\"mnb_sc\", X_training, y_training, X_dev, y_dev, \n",
    "                                                \"c&w n-grams, counts, mult naive bayes\", \n",
    "                                                MultinomialNB(alpha=alpha), \n",
    "                                                k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, alpha, model_acc)\n",
    "summarise_run(\"mnb_sc\") \n",
    "\n",
    "\n",
    "# 1 100 0.606\n",
    "# 1 1000 0.65\n",
    "# 1 10000 0.616\n",
    "# 1 100000 0.624        <-- best, but run was interrupted\n",
    "# 2 100 0.552\n",
    "# 2 1000 0.596\n",
    "# 2 10000 0.574\n",
    "# 2 100000 0.58\n",
    "# 3 100 0.522\n",
    "# 3 1000 0.55\n",
    "# 3 10000 0.57\n",
    "# 3 100000 0.58\n",
    "# 4 100 0.53\n",
    "# 4 1000 0.56\n",
    "# 4 10000 0.556\n",
    "# 4 100000 0.592\n",
    "# 5 100 0.536\n",
    "# 5 100 0.536\n",
    "# 5 1000 0.552\n",
    "# 5 10000 0.556\n",
    "# 5 100000 0.558\n",
    "# 6 100 0.538\n",
    "# 6 1000 0.576\n",
    "# 6 10000 0.544\n",
    "# 6 100000 0.542\n",
    "# Model:    \n",
    "#         knn_sc\n",
    "# Settings: \n",
    "#         {'min_n': 1, 'max_cn': 8, 'min_cn': 1, 'max_n': 6}\n",
    "# Accuracy: \n",
    "#         0.576\n",
    "# [[170  80]\n",
    "#  [132 118]]\n",
    "\n",
    "if do_run(\"knn_sc\"):\n",
    "    for n in [1]\n",
    "        for k in [100000]:\n",
    "            model = SelectCountVectorFeatures(\"knn_sc\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"c&w n-grams, counts, knn\", \n",
    "                                                   KNeighborsClassifier(n_neighbors=n), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(n, k, model_acc)\n",
    "summarise_run(\"knn_sc\") \n",
    "\n",
    "# old\n",
    "# 100 0.5\n",
    "# 1000 0.57\n",
    "# 10000 0.558\n",
    "# 100000 0.628\n",
    "# Model:    \n",
    "#         sgd_sc\n",
    "# Settings: \n",
    "#         {'max_n': 6, 'max_cn': 8, 'min_cn': 1, 'min_n': 1}\n",
    "# Accuracy: \n",
    "#         0.628\n",
    "# [[175  75]\n",
    "#  [111 139]]\n",
    "if do_run(\"sgd_sc\"):\n",
    "    for k in [10000, 100000, 1000000]:\n",
    "        for scaler in zip([StandardScaler(), None], [\"standard\", \"none\"]):\n",
    "            for alpha in 10.0**-np.arange(1,7):\n",
    "                for n_iter in [np.ceil(10**6 / len(X_training))]:  \n",
    "                    model = SelectCountVectorFeatures(\"sgd_sc\", X_training, y_training, X_dev, y_dev, \n",
    "                                                           \"c&w n-grams, counts, sgd\", \n",
    "                                                           SGDClassifier(alpha=alpha,max_iter=n_iter,shuffle=True), \n",
    "                                                           k=k,\n",
    "                                                     scaler=scaler[0])\n",
    "                    model_acc = model.run()\n",
    "                    print(k, scaler[1], alpha, n_iter, model_acc)\n",
    "summarise_run(\"sgd_sc\")\n",
    "\n",
    "# 100 0.1 0.578\n",
    "# 1000 0.1 0.57\n",
    "# 10000 0.1 0.586\n",
    "# 100000 0.1 0.598\n",
    "# Model:    \n",
    "#         nbs_sc\n",
    "# Settings: \n",
    "#         {'max_cn': 8, 'min_n': 1, 'min_cn': 1, 'max_n': 6}\n",
    "# Accuracy: \n",
    "#         0.598\n",
    "# [[138 112]\n",
    "#  [ 89 161]]\n",
    "if do_run(\"nbs_sc\"):\n",
    "    for k in [100000]:\n",
    "        for C in [0.1]:\n",
    "            model = SelectCountVectorFeatures(\"nbs_sc\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"c&w n-grams, counts, naive bayes/svm\", \n",
    "                                                   NBSVM(C=C), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, C, model_acc)\n",
    "summarise_run(\"nbs_sc\")\n",
    "\n",
    "# 100 0.602\n",
    "# 1000 0.6\n",
    "# 10000 0.594\n",
    "# 100000 0.592\n",
    "# Model:    \n",
    "#         xgb_sc\n",
    "# Settings: \n",
    "#         {'min_cn': 1, 'max_cn': 8, 'min_n': 1, 'max_n': 6}\n",
    "# Accuracy: \n",
    "#         0.602\n",
    "# [[169  81]\n",
    "#  [118 132]]\n",
    "if do_run(\"xgb_sc\"):\n",
    "    for k in [100]:\n",
    "        for lr in [0.05]:\n",
    "            for mcw in [1]:\n",
    "                for alpha in [0]:\n",
    "                    model = SelectCountVectorFeatures(\"xgb_sc\", X_training, y_training, X_dev, y_dev, \n",
    "                                                           \"c&w n-grams, counts, xgboost\", \n",
    "                                                           xgb.XGBClassifier(silent=0, learning_rate=lr, min_child_weight=mcw, reg_alpha=alpha), \n",
    "                                                           k=k)\n",
    "                    model_acc = model.run()\n",
    "                    print(k, lr, mcw, alpha, model_acc)\n",
    "summarise_run(\"xgb_sc\")\n",
    "\n",
    "if do_run(\"lsc_sc\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        for C in [0.1, 0.5, 1.0]:\n",
    "            model = SelectCountVectorFeatures(\"lsc_sc\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"c&w n-grams, count, linear svc\", \n",
    "                                                   LinearSVC(C=C), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, C, model_acc)\n",
    "summarise_run(\"lsc_sc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the same material but with tf-idf instead of raw counts. Not even normalised vectors were used in the previous experiments. YOLO(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# old info\n",
    "# 100 0.628\n",
    "# 1000 0.644\n",
    "# 10000 0.638\n",
    "# 100000 0.63\n",
    "# Model:    \n",
    "#         rfo_st\n",
    "# Settings: \n",
    "#         {'min_n': 1, 'max_n': 6, 'min_cn': 1, 'max_cn': 8}\n",
    "# Accuracy: \n",
    "#         0.644\n",
    "# [[181  69]\n",
    "#  [109 141]]\n",
    "if do_run(\"rfo_st\"):\n",
    "    for k in [1000, 10000]:\n",
    "        for max_features in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "            for n_estimators in [10, 50, 100, 150, 200, 250]:\n",
    "                for min_sample_leaf in [10, 25, 50, 75, 100, 250]:\n",
    "                    for n_jobs in [30]:\n",
    "                        print(max_features, n_estimators, min_sample_leaf, n_jobs)\n",
    "                        model = SelectTfidfVectorFeatures(\"rfo_st\", X_training, y_training, X_dev, y_dev, \n",
    "                                                          \"c&w n-grams, tfidf, random forests\",\n",
    "                                                          RandomForestClassifier(max_features=max_features,\n",
    "                                                                                n_estimators=n_estimators,\n",
    "                                                                                min_samples_leaf=min_sample_leaf,\n",
    "                                                                                n_jobs=n_jobs,\n",
    "                                                                                random_state=571989,\n",
    "                                                                                oob_score=True), \n",
    "                                                          k=k)\n",
    "                        model_acc = model.run()\n",
    "                        print(k, model_acc)        \n",
    "summarise_run(\"rfo_st\")\n",
    "\n",
    "\n",
    "# FINAL\n",
    "# 100 0 0.546\n",
    "# 100 0.001 0.546\n",
    "# 100 0.05 0.546\n",
    "# 100 0.5 0.546\n",
    "# 100 1.0 0.546\n",
    "# 100 1.5 0.54\n",
    "# 100 2.5 0.54\n",
    "# 1000 0 0.564\n",
    "# 1000 0.001 0.564\n",
    "# 1000 0.05 0.564\n",
    "# 1000 0.5 0.562\n",
    "# 1000 1.0 0.566\n",
    "# 1000 1.5 0.564\n",
    "# 1000 2.5 0.56\n",
    "# 10000 0 0.594\n",
    "# 10000 0.001 0.594\n",
    "# 10000 0.05 0.592\n",
    "# 10000 0.5 0.594\n",
    "# 10000 1.0 0.596\n",
    "# 10000 1.5 0.594\n",
    "# 10000 2.5 0.584\n",
    "# 100000 0 0.618\n",
    "# 100000 0.001 0.616\n",
    "# 100000 0.05 0.614\n",
    "# 100000 0.5 0.616\n",
    "# 100000 1.0 0.616\n",
    "# 100000 1.5 0.608\n",
    "# 100000 2.5 0.604\n",
    "# 1000000 0 0.666\n",
    "# 1000000 0.001 0.64\n",
    "# 1000000 0.05 0.634\n",
    "# 1000000 0.5 0.616\n",
    "# 1000000 1.0 0.608\n",
    "# 1000000 1.5 0.602\n",
    "# 1000000 2.5 0.592\n",
    "# all 0 0.682\n",
    "# all 0.001 0.688\n",
    "# all 0.05 0.698\n",
    "# all 0.5 0.666\n",
    "# all 1.0 0.638\n",
    "# all 1.5 0.622\n",
    "# all 2.5 0.616\n",
    "# Model:    \n",
    "#         mnb_st\n",
    "# Accuracy: \n",
    "#         0.698\n",
    "# [[178  72]\n",
    "#  [ 79 171]]\n",
    "if do_run(\"mnb_st\"):\n",
    "    for k in ['all']:\n",
    "        for alpha in [0.05]:\n",
    "            model = SelectTfidfVectorFeatures(\"mnb_st\", X_training, y_training, X_dev, y_dev, \n",
    "                                                \"c&w n-grams, tfidf, mult naive bayes\", \n",
    "                                                MultinomialNB(alpha=alpha), \n",
    "                                                k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, alpha, model_acc)\n",
    "summarise_run(\"mnb_st\") \n",
    "\n",
    "# old\n",
    "# 1 100 0.632\n",
    "# 1 1000 0.64\n",
    "# 1 10000 0.648       <-- best, but run was interrupted\n",
    "# 1 100000 0.636\n",
    "# 2 100 0.526\n",
    "# 2 1000 0.564\n",
    "# 2 10000 0.612\n",
    "# 2 100000 0.574\n",
    "# 3 100 0.558\n",
    "# 3 1000 0.6\n",
    "# 3 10000 0.612\n",
    "# 3 100000 0.552\n",
    "# 4 100 0.526\n",
    "# 4 1000 0.584\n",
    "# 4 10000 0.598\n",
    "# 4 100000 0.548\n",
    "# 5 100 0.584\n",
    "# 5 1000 0.59\n",
    "# 5 10000 0.626\n",
    "# 5 100000 0.538\n",
    "# 6 100 0.558\n",
    "# 6 1000 0.592\n",
    "# 6 10000 0.586\n",
    "# 6 100000 0.506\n",
    "# Model:    \n",
    "#         knn_st\n",
    "# Settings: \n",
    "#         {'min_cn': 1, 'max_cn': 8, 'min_n': 1, 'max_n': 6}\n",
    "# Accuracy: \n",
    "#         0.626\n",
    "# [[162  88]\n",
    "#  [ 99 151]]\n",
    "if do_run(\"knn_st\"):\n",
    "    for n in [1,3,5,7,9]:\n",
    "        for k in ['all']:\n",
    "            for algorithm in ['ball_tree', 'kd_tree']:\n",
    "                for weights in ['uniform', 'distance']:\n",
    "                    model = SelectTfidfVectorFeatures(\"knn_st\", X_training, y_training, X_dev, y_dev, \n",
    "                                                           \"c&w n-grams, tfidf, knn\", \n",
    "                                                           KNeighborsClassifier(n_neighbors=n,\n",
    "                                                           algorithm=algorithm,\n",
    "                                                      n_jobs=30,\n",
    "                                                      weights=weights),\n",
    "                                                           k=k)\n",
    "                    model_acc = model.run()\n",
    "                    print(n, k, algorithm, weights, model_acc)\n",
    "summarise_run(\"knn_st\") \n",
    "\n",
    "# FINAL\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.1 4.0 0.596\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.01 4.0 0.608\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.001 4.0 0.608\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.0001 4.0 0.594\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-05 4.0 0.59\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-06 4.0 0.542\n",
    "# 10000 None 0.1 4.0 0.5\n",
    "# 10000 None 0.01 4.0 0.5\n",
    "# 10000 None 0.001 4.0 0.544\n",
    "# 10000 None 0.0001 4.0 0.582\n",
    "# 10000 None 1e-05 4.0 0.604\n",
    "# 10000 None 1e-06 4.0 0.616\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.1 4.0 0.62\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.01 4.0 0.624\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.001 4.0 0.604\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.0001 4.0 0.614\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-05 4.0 0.606\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-06 4.0 0.594\n",
    "# 100000 None 0.1 4.0 0.5\n",
    "# 100000 None 0.01 4.0 0.544\n",
    "# 100000 None 0.001 4.0 0.562\n",
    "# 100000 None 0.0001 4.0 0.576\n",
    "# 100000 None 1e-05 4.0 0.626\n",
    "# 100000 None 1e-06 4.0 0.634\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.1 4.0 0.654\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.01 4.0 0.674\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.001 4.0 0.652\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.0001 4.0 0.648\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-05 4.0 0.652\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-06 4.0 0.66\n",
    "# 1000000 None 0.1 4.0 0.5\n",
    "# 1000000 None 0.01 4.0 0.5\n",
    "# 1000000 None 0.001 4.0 0.558\n",
    "# 1000000 None 0.0001 4.0 0.578\n",
    "# 1000000 None 1e-05 4.0 0.626\n",
    "# 1000000 None 1e-06 4.0 0.682\n",
    "# Model:    \n",
    "#         sgd_st\n",
    "# Accuracy: \n",
    "#         0.682\n",
    "# [[161  89]\n",
    "#  [ 70 180]]\n",
    "if do_run(\"sgd_st\"):\n",
    "    for k in [10000, 100000, 1000000]:\n",
    "        for scaler in zip([StandardScaler(), None], [\"standard\", \"none\"]):\n",
    "            for alpha in 10.0**-np.arange(1,7):\n",
    "                for n_iter in [np.ceil(10**6 / len(X_training))]:  \n",
    "                    model = SelectTfidfVectorFeatures(\"sgd_st\", X_training, y_training, X_dev, y_dev, \n",
    "                                                           \"c&w n-grams, tfidf, sgd\",\n",
    "                                                           SGDClassifier(alpha=alpha,max_iter=n_iter,shuffle=True), \n",
    "                                                           k=k,\n",
    "                                                     scaler=scaler[0])\n",
    "                    model_acc = model.run()\n",
    "                    print(k, scaler[1], alpha, n_iter, model_acc)\n",
    "summarise_run(\"sgd_st\")\n",
    "\n",
    "# 100 0.598\n",
    "# 1000 0.584\n",
    "# 10000 0.594\n",
    "# 100000 0.588\n",
    "# Model:    \n",
    "#         xgb_st\n",
    "# Settings: \n",
    "#         {'max_cn': 8, 'max_n': 6, 'min_n': 1, 'min_cn': 1}\n",
    "# Accuracy: \n",
    "#         0.598\n",
    "# [[163  87]\n",
    "#  [114 136]]\n",
    "if do_run(\"xgb_st\"):\n",
    "    for k in [100]:\n",
    "        model = SelectTfidfVectorFeatures(\"xgb_st\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"c&w n-grams, tfidf, xgboost\", \n",
    "                                               xgb.XGBClassifier(), \n",
    "                                               k=k)\n",
    "        model_acc = model.run()\n",
    "        print(k, model_acc)\n",
    "summarise_run(\"xgb_st\")\n",
    "\n",
    "\n",
    "# 100 0.1 0.582\n",
    "# 1000 0.1 0.584\n",
    "# 10000 0.1 0.61\n",
    "# 100000 0.1 0.608\n",
    "# Model:    \n",
    "#         nbs_st\n",
    "# Settings: \n",
    "#         {'min_n': 1, 'max_cn': 8, 'max_n': 6, 'min_cn': 1}\n",
    "# Accuracy: \n",
    "#         0.61\n",
    "# [[133 117]\n",
    "#  [ 78 172]]\n",
    "if do_run(\"nbs_st\"):\n",
    "    for k in [10000]:\n",
    "        for C in [0.1]:\n",
    "            model = SelectTfidfVectorFeatures(\"nbs_st\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"c&w n-grams, tfidf, naive bayes/svm\", \n",
    "                                                   NBSVM(C=C), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, C, model_acc)\n",
    "summarise_run(\"nbs_st\")\n",
    "\n",
    "if do_run(\"xgb_st1\"):\n",
    "    for k in [1000, 10000]:\n",
    "        for max_depth in [3, 5, 7, 10, 15]:\n",
    "            for learning_rate in [0.01, 0.05, 0.1, 0.25, 0.4, 0.5]:\n",
    "                for min_child_weight in [1, 10, 25, 50]:\n",
    "                    for subsample in [0.5, 0.75, 0.9]:\n",
    "                        for alpha in [0.1, 0.25, 0.5, 0.75]:\n",
    "                            model = SelectTfidfVectorFeatures(\"xgb_st\", X_training, y_training, X_dev, y_dev, \n",
    "                                                                   \"c&w n-grams, tfidf, xgboost\", \n",
    "                                                                   xgb.XGBClassifier(silent=0,\n",
    "                                                                                     max_depth=max_depth\n",
    "                                                                                     learning_rate=learning_rate, \n",
    "                                                                                     min_child_weight=min_child_weight, \n",
    "                                                                                     reg_alpha=alpha,\n",
    "                                                                                     subsample=subsample), \n",
    "                                                                   k=k)\n",
    "                            model_acc = model.run()\n",
    "                            print(k, max_depth, learning_rate, min_child_weight, subsample, alpha, model_acc)\n",
    "summarise_run(\"xgb_st\")\n",
    "\n",
    "# 100 0.1 0.598\n",
    "# 100 0.5 0.586\n",
    "# 100 1.0 0.586\n",
    "# 1000 0.1 0.57\n",
    "# 1000 0.5 0.582\n",
    "# 1000 1.0 0.578\n",
    "# 10000 0.1 0.63\n",
    "# 10000 0.5 0.626\n",
    "# 10000 1.0 0.626\n",
    "# 100000 0.1 0.624\n",
    "# 100000 0.5 0.622\n",
    "# 100000 1.0 0.61\n",
    "# Model:    \n",
    "#         lsc_st\n",
    "# Settings: \n",
    "#         {'min_cn': 1, 'min_n': 1, 'max_cn': 8, 'max_n': 6}\n",
    "# Accuracy: \n",
    "#         0.63\n",
    "# [[166  84]\n",
    "#  [101 149]\n",
    "if do_run(\"lsc_st\"):\n",
    "    for k in [10000]:\n",
    "        for C in [0.1]:\n",
    "            model = SelectTfidfVectorFeatures(\"lsc_st\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"c&w n-grams, tfidf, linear svc\", \n",
    "                                                   LinearSVC(C=C), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, C, model_acc)\n",
    "summarise_run(\"lsc_st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Features\n",
    "Part of speech, piece of shit, positively outstanding service? I don't know. They don't really contribute, that's all I know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "if do_run(\"rfo_pos\"):\n",
    "    for k in [1000, 10000]:\n",
    "        for max_features in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "            for n_estimators in [10, 50, 100, 150, 200, 250]:\n",
    "                for min_sample_leaf in [10, 25, 50, 75, 100, 250]:\n",
    "                    for n_jobs in [30]:\n",
    "                        print(max_features, n_estimators, min_sample_leaf, n_jobs)\n",
    "                        model = SelectPOSVectorFeatures(\"rfo_pos\", X_training, y_training, X_dev, y_dev, \n",
    "                                                          \"pos n-grams, counts, random forests\", \n",
    "                                                          RandomForestClassifier(max_features=max_features,\n",
    "                                                                                n_estimators=n_estimators,\n",
    "                                                                                min_samples_leaf=min_sample_leaf,\n",
    "                                                                                n_jobs=n_jobs,\n",
    "                                                                                random_state=571989,\n",
    "                                                                                oob_score=True), \n",
    "                                                          k=k)\n",
    "                        model_acc = model.run()\n",
    "                        print(k, model_acc)\n",
    "summarise_run(\"rfo_pos\")\n",
    "\n",
    "# FINAL\n",
    "# 100 0 0.51\n",
    "# 100 0.001 0.51\n",
    "# 100 0.05 0.51\n",
    "# 100 0.5 0.51\n",
    "# 100 1.0 0.51\n",
    "# 100 1.5 0.508\n",
    "# 100 2.5 0.508\n",
    "# 1000 0 0.56\n",
    "# 1000 0.001 0.56\n",
    "# 1000 0.05 0.562\n",
    "# 1000 0.5 0.56\n",
    "# 1000 1.0 0.56\n",
    "# 1000 1.5 0.556\n",
    "# 1000 2.5 0.554\n",
    "# 10000 0 0.602\n",
    "# 10000 0.001 0.602\n",
    "# 10000 0.05 0.604\n",
    "# 10000 0.5 0.6\n",
    "# 10000 1.0 0.6\n",
    "# 10000 1.5 0.594\n",
    "# 10000 2.5 0.582\n",
    "# 100000 0 0.608\n",
    "# 100000 0.001 0.606\n",
    "# 100000 0.05 0.606\n",
    "# 100000 0.5 0.592\n",
    "# 100000 1.0 0.58\n",
    "# 100000 1.5 0.584\n",
    "# 100000 2.5 0.576\n",
    "# 1000000 0 0.684\n",
    "# 1000000 0.001 0.678\n",
    "# 1000000 0.05 0.668\n",
    "# 1000000 0.5 0.65\n",
    "# 1000000 1.0 0.626\n",
    "# 1000000 1.5 0.614\n",
    "# 1000000 2.5 0.602\n",
    "# all 0 0.688\n",
    "# all 0.001 0.69\n",
    "# all 0.05 0.686\n",
    "# all 0.5 0.678\n",
    "# all 1.0 0.672\n",
    "# all 1.5 0.668\n",
    "# all 2.5 0.66\n",
    "# Model:    \n",
    "#         mnb_pos\n",
    "# Accuracy: \n",
    "#         0.69\n",
    "# [[168  82]\n",
    "#  [ 73 177]]\n",
    "if do_run(\"mnb_pos\"):\n",
    "    for k in ['all']:\n",
    "        for alpha in [0]:\n",
    "            model = SelectPOSVectorFeatures(\"mnb_pos\", X_training, y_training, X_dev, y_dev, \n",
    "                                            \"pos n-grams, counts, mult naive bayes\", \n",
    "                                            MultinomialNB(alpha=alpha), \n",
    "                                            k=k)\n",
    "        model_acc = model.run()\n",
    "        print(k, alpha, model_acc)\n",
    "summarise_run(\"mnb_pos\") \n",
    "\n",
    "\n",
    "if do_run(\"knn_pos\"):\n",
    "    for n in [1, 2, 3, 4, 5, 6]\n",
    "        for k in [100, 1000, 10000, 100000]:\n",
    "            model = SelectPOSVectorFeatures(\"knn_pos\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"pos n-grams, counts, knn\", \n",
    "                                                   KNeighborsClassifier(n_neighbors=n), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(n, k, model_acc)\n",
    "summarise_run(\"knn_pos\") \n",
    "\n",
    "# FINAL\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.1 4.0 0.556\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.01 4.0 0.542\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.001 4.0 0.54\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.0001 4.0 0.54\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-05 4.0 0.534\n",
    "# 10000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-06 4.0 0.534\n",
    "# 10000 None 0.1 4.0 0.5\n",
    "# 10000 None 0.01 4.0 0.5\n",
    "# 10000 None 0.001 4.0 0.534\n",
    "# 10000 None 0.0001 4.0 0.544\n",
    "# 10000 None 1e-05 4.0 0.578\n",
    "# 10000 None 1e-06 4.0 0.574\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.1 4.0 0.608\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.01 4.0 0.606\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.001 4.0 0.614\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.0001 4.0 0.608\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-05 4.0 0.616\n",
    "# 100000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-06 4.0 0.616\n",
    "# 100000 None 0.1 4.0 0.5\n",
    "# 100000 None 0.01 4.0 0.5\n",
    "# 100000 None 0.001 4.0 0.5\n",
    "# 100000 None 0.0001 4.0 0.556\n",
    "# 100000 None 1e-05 4.0 0.576\n",
    "# 100000 None 1e-06 4.0 0.596\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.1 4.0 0.684\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.01 4.0 0.678\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.001 4.0 0.668\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 0.0001 4.0 0.662\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-05 4.0 0.69\n",
    "# 1000000 StandardScaler(copy=True, with_mean=False, with_std=True) 1e-06 4.0 0.676\n",
    "# 1000000 None 0.1 4.0 0.5\n",
    "# 1000000 None 0.01 4.0 0.5\n",
    "# 1000000 None 0.001 4.0 0.5\n",
    "# 1000000 None 0.0001 4.0 0.55\n",
    "# 1000000 None 1e-05 4.0 0.578\n",
    "# 1000000 None 1e-06 4.0 0.632\n",
    "# all StandardScaler(copy=True, with_mean=False, with_std=True) 0.1 4.0 0.66\n",
    "# all StandardScaler(copy=True, with_mean=False, with_std=True) 0.01 4.0 0.664\n",
    "# all StandardScaler(copy=True, with_mean=False, with_std=True) 0.001 4.0 0.67\n",
    "# all StandardScaler(copy=True, with_mean=False, with_std=True) 0.0001 4.0 0.674\n",
    "# all StandardScaler(copy=True, with_mean=False, with_std=True) 1e-05 4.0 0.686\n",
    "# all StandardScaler(copy=True, with_mean=False, with_std=True) 1e-06 4.0 0.694\n",
    "# all None 0.1 4.0 0.5\n",
    "# all None 0.01 4.0 0.5\n",
    "# all None 0.001 4.0 0.5\n",
    "# all None 0.0001 4.0 0.546\n",
    "# all None 1e-05 4.0 0.612\n",
    "# all None 1e-06 4.0 0.672\n",
    "# Model:    \n",
    "#         sgd_pos\n",
    "# Accuracy: \n",
    "#         0.694\n",
    "# [[171  79]\n",
    "#  [ 74 176]]\n",
    "if do_run(\"sgd_pos\"):\n",
    "    for k in ['all']:\n",
    "        for scaler in [StandardScaler(with_mean=False)]:\n",
    "            for alpha in [10.0**-7:]:#10.0**-np.arange(1,7):\n",
    "                for n_iter in [np.ceil(10**6 / len(X_training))]:  \n",
    "                    model = SelectPOSVectorFeatures(\"sgd_pos\", X_training, y_training, X_dev, y_dev, \n",
    "                                                           \"pos n-grams, counts, sgd\", \n",
    "                                                           SGDClassifier(alpha=alpha,max_iter=n_iter,shuffle=True), \n",
    "                                                           k=k,\n",
    "                                                     scaler=scaler)\n",
    "                    model_acc = model.run()\n",
    "                    print(k, scaler, alpha, n_iter, model_acc)\n",
    "summarise_run(\"sgd_pos\")\n",
    "\n",
    "\n",
    "if do_run(\"nbs_pos\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        for C in [0.1]:\n",
    "            model = SelectPOSVectorFeatures(\"nbs_pos\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"pos n-grams, counts, naive bayes/svm\", \n",
    "                                                   NBSVM(C=C), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, C, model_acc)\n",
    "summarise_run(\"nbs_pos\")\n",
    "\n",
    "\n",
    "if do_run(\"xgb_pos\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        for lr in [0.05]:\n",
    "            for mcw in [1]:\n",
    "                for alpha in [0]:\n",
    "                    model = SelectPOSVectorFeatures(\"xgb_pos\", X_training, y_training, X_dev, y_dev, \n",
    "                                                           \"pos n-grams, counts, xgboost\", \n",
    "                                                           xgb.XGBClassifier(silent=0, learning_rate=lr, min_child_weight=mcw, reg_alpha=alpha), \n",
    "                                                           k=k)\n",
    "                    model_acc = model.run()\n",
    "                    print(k, lr, mcw, alpha, model_acc)\n",
    "summarise_run(\"xgb_pos\")\n",
    "\n",
    "if do_run(\"lsc_pos\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        for C in [0.1, 0.5, 1.0]:\n",
    "            model = SelectPOSVectorFeatures(\"lsc_pos\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"pos n-grams, count, linear svc\", \n",
    "                                                   LinearSVC(C=C), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, C, model_acc)\n",
    "summarise_run(\"lsc_pos\")\n",
    "\n",
    "if do_run(\"lgb_pos\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        for n_estimators in [5, 25, 50, 75, 100, 125, 150, 250]:\n",
    "            for max_depth in [2, 3, 4, 5, 6, 7, 8]:\n",
    "                for boosting_type in ['gbdt', 'dart']:\n",
    "                    model = SelectPOSVectorFeatures(\"lgb_pos\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"pos n-grams, count, lightgbm\", \n",
    "                                               lgb.LGBMRegressor(n_estimators=n_estimators, \n",
    "                                                                 max_depth=max_depth,\n",
    "                                                                boosting_type=boosting_type,\n",
    "                                                                n_jobs=30,\n",
    "                                                                random_state=571989), \n",
    "                                               k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, n_estimators, max_depth, boosting_type, model_acc)\n",
    "summarise_run(\"lgb_pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loglikelihood-based features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a new vectoriser based on the loglikelihood values as computed by [colibricore-loglikelihood](https://github.com/proycon/colibri-core/blob/master/scripts/colibri-loglikelihood).\n",
    "Based on some thresholds (n-gram occurrence $\\ge 2$, $1 \\le n \\le 3$ -grams), it computes the occurrence counts,\n",
    "their frequency and the corresponding loglikelihood scores.\n",
    "These scores are sorted, and then this vectoriser takes the top m patterns, and marks whether that pattern\n",
    "is presented in the given set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "class LLHbasedBinaryVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, count=1000):\n",
    "        self.llh_1000 = []\n",
    "        with open('data/DUT_BEL.t5m1l6.llh_t', 'r') as f:\n",
    "            for n, line in enumerate(f):\n",
    "                self.llh_1000.append(line.split(\"\\t\")[0])\n",
    "                if count != \"all\" and n >= count:\n",
    "                    break\n",
    "    \n",
    "    def llh_binary_countvectorizer(self, line):\n",
    "        values = []\n",
    "        for k in self.llh_1000:\n",
    "            values.append(1*(k in line))\n",
    "        return lil_matrix(values)\n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        result = csr_matrix((len(df),len(self.llh_1000)))\n",
    "        for r, l in enumerate(df):\n",
    "            result[r,:] = self.llh_binary_countvectorizer(l)\n",
    "        return result\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLHbasedFeatures():\n",
    "    \n",
    "    def __init__(self, name, X, Y, x, y, description, classifier, feature_selection = None, scaler = None, k=1000):\n",
    "        self.run_name = name\n",
    "        self.run_description = description\n",
    "        \n",
    "        self.classifier = classifier\n",
    "        self.features = [('llh', LLHbasedBinaryVectorizer(count=k)),\n",
    "                    #('words', TfidfVectorizer(analyzer='word', ngram_range=(min_n,max_n),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))\n",
    "                   ]\n",
    "        self.feature_selection = feature_selection\n",
    "        self.scaler = scaler\n",
    "    \n",
    "        self.k = k\n",
    "    \n",
    "        register_run(self.run_name, self.run_description, [])\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        #print(\"Classifier:\", self.classifier)\n",
    "        #print(\"Feature extraction:\", self.features)\n",
    "        #print(\"Feature selection:\", self.feature_selection)\n",
    "        #print(\"Feature scaler:\", self.scaler)\n",
    "                \n",
    "        self.pipeline = Pipeline([\n",
    "            ('features',   FeatureUnion(self.features)),\n",
    "            ('scaler',     self.scaler),\n",
    "            ('selection',  self.feature_selection),\n",
    "            ('classifier', self.classifier),\n",
    "        ])\n",
    "\n",
    "        model = self.pipeline.fit(X_training, y_training)\n",
    "        self.y_pred = model.predict(X_dev)\n",
    "\n",
    "        update_stats(self.run_name, y_dev, self.y_pred, {'k': self.k})\n",
    "        \n",
    "        return accuracy_score(y_dev, self.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# 100 0.63\n",
    "# 1000 0.636\n",
    "# 10000 0.63\n",
    "# 100000 0.676\n",
    "# Model:    \n",
    "#         rfo_llh\n",
    "# Settings: \n",
    "#         {'k': 100000}\n",
    "# Accuracy: \n",
    "#         0.676\n",
    "# [[183  67]\n",
    "#  [ 95 155]]\n",
    "if do_run(\"rfo_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        model = LLHbasedFeatures(\"rfo_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                            \"c&w n-grams, llh, random forests\", \n",
    "                                            RandomForestClassifier(), \n",
    "                                            k=k)\n",
    "        model_acc = model.run()\n",
    "        print(k, model_acc)\n",
    "summarise_run(\"rfo_llh\")\n",
    "\n",
    "# 100 0.6\n",
    "# 1000 0.576\n",
    "# 10000 0.622\n",
    "# 100000 0.628\n",
    "# Model:    \n",
    "#         mnb_llh\n",
    "# Settings: \n",
    "#         {'k': 100000}\n",
    "# Accuracy: \n",
    "#         0.628\n",
    "# [[154  96]\n",
    "#  [ 90 160]]\n",
    "if do_run(\"mnb_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000, 1000000, 'all']:\n",
    "        for alpha in [0, 0.001, 0.05, 0.5, 1.0, 1.5, 2.5]:\n",
    "            model = LLHbasedFeatures(\"mnb_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                            \"c&w n-grams, llh, mult naive bayes\", \n",
    "                                            MultinomialNB(alpha=alpha), \n",
    "                                            k=k)\n",
    "        model_acc = model.run()\n",
    "        print(k, alpha, model_acc)\n",
    "summarise_run(\"mnb_llh\") \n",
    "\n",
    "if do_run(\"knn_llh\"):\n",
    "    for n in [1,3,5,7,9]:\n",
    "        for k in ['all']:\n",
    "            for algorithm in ['ball_tree', 'kd_tree']:\n",
    "                for weights in ['uniform', 'distance']:\n",
    "                    model = LLHbasedFeatures(\"knn_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                                           \"c&w n-grams, llh, knn\", \n",
    "                                                           KNeighborsClassifier(n_neighbors=n,\n",
    "                                                           algorithm=algorithm,\n",
    "                                                      n_jobs=30,\n",
    "                                                      weights=weights),\n",
    "                                                           k=k)\n",
    "                    model_acc = model.run()\n",
    "                    print(n, k, algorithm, weights, model_acc)\n",
    "summarise_run(\"knn_llh\") \n",
    "\n",
    "# 100 0.582\n",
    "# 1000 0.6\n",
    "# 10000 0.604\n",
    "# 100000 0.6\n",
    "# Model:    \n",
    "#         sgd_llh\n",
    "# Settings: \n",
    "#         {'k': 10000}\n",
    "# Accuracy: \n",
    "#         0.604\n",
    "# [[201  49]\n",
    "#  [149 101]]\n",
    "if do_run(\"sgd_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        model = LLHbasedFeatures(\"sgd_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"c&w n-grams, llh, sgd\", \n",
    "                                               SGDClassifier(), \n",
    "                                               k=k)\n",
    "        model_acc = model.run()\n",
    "        print(k, model_acc)\n",
    "summarise_run(\"sgd_llh\")\n",
    "\n",
    "# 100 0.566\n",
    "# 1000 0.59\n",
    "# 10000 0.62\n",
    "# 100000 0.616\n",
    "# Model:    \n",
    "#         log_llh\n",
    "# Settings: \n",
    "#         {'k': 10000}\n",
    "# Accuracy: \n",
    "#         0.62\n",
    "# [[140 110]\n",
    "#  [ 80 170]]\n",
    "if do_run(\"log_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        model = LLHbasedFeatures(\"log_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"c&w n-grams, llh, logit\", \n",
    "                                               SGDClassifier(loss=\"log\"), \n",
    "                                               k=k)\n",
    "        model_acc = model.run()\n",
    "        print(k, model_acc)\n",
    "summarise_run(\"log_llh\")\n",
    "\n",
    "# 100 0.504\n",
    "# 1000 0.558\n",
    "# 10000 0.562\n",
    "# 100000 0.582\n",
    "# Model:    \n",
    "#         pct_llh\n",
    "# Settings: \n",
    "#         {'k': 100000}\n",
    "# Accuracy: \n",
    "#         0.582\n",
    "# [[106 144]\n",
    "#  [ 65 185]]\n",
    "if do_run(\"pct_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        model = LLHbasedFeatures(\"pct_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"c&w n-grams, llh, perceptron\", \n",
    "                                               SGDClassifier(loss=\"perceptron\"), \n",
    "                                               k=k)\n",
    "        model_acc = model.run()\n",
    "        print(k, model_acc)\n",
    "summarise_run(\"pct_llh\")\n",
    "\n",
    "# 100 0.1 0.606\n",
    "# 1000 0.1 0.624\n",
    "# 10000 0.1 0.62\n",
    "# 100000 0.1 0.608\n",
    "# Model:    \n",
    "#         nbs_llh\n",
    "# Settings: \n",
    "#         {'k': 1000}\n",
    "# Accuracy: \n",
    "#         0.624\n",
    "# [[162  88]\n",
    "#  [100 150]]\n",
    "if do_run(\"nbs_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        for C in [0.1]:\n",
    "            model = LLHbasedFeatures(\"nbs_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"c&w n-grams, llh, naive bayes/svm\", \n",
    "                                                   NBSVM(C=C), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, C, model_acc)\n",
    "summarise_run(\"nbs_llh\")\n",
    "\n",
    "if do_run(\"xgb_llh\"):\n",
    "    for k in [100000]:\n",
    "        for lr in [0.05]:\n",
    "            for mcw in [1]:\n",
    "                for alpha in [0]:\n",
    "                    model = LLHbasedFeatures(\"xgb_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                                           \"c&w n-grams, llh, xgboost\", \n",
    "                                                           xgb.XGBClassifier(silent=0, learning_rate=lr, min_child_weight=mcw, reg_alpha=alpha), \n",
    "                                                           k=k)\n",
    "                    model_acc = model.run()\n",
    "                    print(k, lr, mcw, alpha, model_acc)\n",
    "summarise_run(\"xgb_llh\")\n",
    "\n",
    "if do_run(\"lsc_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        for C in [0.1, 0.5, 1.0]:\n",
    "            model = LLHbasedFeatures(\"lsc_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"c&w n-grams, llh, linear svc\", \n",
    "                                                   LinearSVC(C=C), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, C, model_acc)\n",
    "summarise_run(\"lsc_llh\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "if do_run(\"lgbm_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        for n_estimators in [5, 25, 50, 75, 100, 125, 150, 250]:\n",
    "            for max_depth in [2, 3, 4, 5, 6, 7, 8]:\n",
    "                for boosting_type in ['gbdt', 'dart']:\n",
    "                    model = LLHbasedFeatures(\"lgbm_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"c&w n-grams, llh, lightgbm\", \n",
    "                                               lgb.LGBMRegressor(n_estimators=n_estimators, \n",
    "                                                                 max_depth=max_depth,\n",
    "                                                                boosting_type=boosting_type,\n",
    "                                                                n_jobs=30,\n",
    "                                                                random_state=571989), \n",
    "                                               k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, n_estimators, max_depth, boosting_type, model_acc)\n",
    "summarise_run(\"lgbm_llh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding features\n",
    "No experiment these days is complete without using embeddings. It's fancier than the multilayer perceptron that we're using. [Fasttext](https://github.com/facebookresearch/fastText) seems to work quite well actually. \"Thank you Facebook.\" There, I said it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "# Model:    \n",
    "#         fat1\n",
    "# Settings: \n",
    "#         {}\n",
    "# Accuracy: \n",
    "#         0.692\n",
    "# [[162  88]\n",
    "#  [ 66 184]]\n",
    "if do_run(\"fat1\"):\n",
    "    \n",
    "    register_run(\"fat1\",\n",
    "             \"character and word n-grams, with embeddings, used in a fasttext (w2v sg) setting\",\n",
    "             [])\n",
    "\n",
    "    with open('fasttext.train.txt', 'w') as f:\n",
    "        for line, label in zip(X_training, y_training):\n",
    "            f.write(line + \" __language__\" + label + \"\\n\")\n",
    "\n",
    "    ft_classifier = fasttext.supervised('fasttext.train.txt', 'model', \n",
    "                                        min_count=1, \n",
    "                                        word_ngrams=5, \n",
    "                                        epoch=100,\n",
    "                                        minn=3, \n",
    "                                        maxn=7, \n",
    "                                        thread=2, \n",
    "                                        dim=250,\n",
    "                                        ws=5,\n",
    "                                        bucket= 2000000,\n",
    "                                        label_prefix='__language__')\n",
    "    ft_predictions = ft_classifier.predict(X_dev)\n",
    "    \n",
    "    update_stats(\"fat1\", y_dev, ft_predictions, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language model-based features\n",
    "Since I'm doing my PhD in language models it would be a disgrace and completely embarrassing if I didn't use some form of proper old-school frequentist markov-chain language modelling. \"That thing\" people used before neural language models were so widespread and (to my dismay) this well performing. In our case we're using a 4-gram modified kneser-ney implementation. In the first experiment trained on either of the languages, and in the second experiment on both languages where we overtrained (overfitted?) on either language. Hint, the first one works best. Kids, duplicating data is never a good idea for language models! Don't do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "\n",
    "_run_stats.pop('mkn_lm', None)\n",
    "summarise_run(\"mkn_lm\")\n",
    "\n",
    "if do_run(\"mkn_lm\"):\n",
    "    \n",
    "    register_run(\"mkn_lm\",\n",
    "             \"word 4-grams, in a modified kneser ney setting\",\n",
    "             [])\n",
    "    \n",
    "    lm_bel = kenlm.LanguageModel('data/train.BEL.arpa')\n",
    "    print('{0}-gram model'.format(lm_bel.order))\n",
    "\n",
    "    lm_dut = kenlm.LanguageModel('data/train.DUT.arpa')\n",
    "    print('{0}-gram model'.format(lm_dut.order))\n",
    "\n",
    "    lm_result = []\n",
    "    for sent in X_dev:\n",
    "        if lm_bel.score(sent) < lm_dut.score(sent): # closer to zero is better\n",
    "            lm_result.append(\"DUT\")\n",
    "        else:\n",
    "            lm_result.append(\"BEL\")\n",
    "    \n",
    "    update_stats(\"mkn_lm\", y_dev, np.array(lm_result), {'order': lm_bel.order})\n",
    "    \n",
    "summarise_run(\"mkn_lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "\n",
    "_run_stats.pop('mkn_lm2', None)\n",
    "summarise_run(\"mkn_lm2\")\n",
    "\n",
    "if do_run(\"mkn_lm2\"):\n",
    "    \n",
    "    register_run(\"mkn_lm2\",\n",
    "             \"word 4-grams, in a modified kneser ney setting, trained on both, overtrained on one\",\n",
    "             [])\n",
    "    \n",
    "    lm_bel = kenlm.LanguageModel('data/train.DUTBELBELBEL.arpa')\n",
    "    print('{0}-gram model'.format(lm_bel.order))\n",
    "\n",
    "    lm_dut = kenlm.LanguageModel('data/train.BELDUTDUTDUT.arpa')\n",
    "    print('{0}-gram model'.format(lm_dut.order))\n",
    "\n",
    "    lm_result = []\n",
    "    for sent in X_dev:\n",
    "        if lm_bel.score(sent) < lm_dut.score(sent): # closer to zero is better\n",
    "            lm_result.append(\"DUT\")\n",
    "        else:\n",
    "            lm_result.append(\"BEL\")\n",
    "    \n",
    "    update_stats(\"mkn_lm2\", y_dev, np.array(lm_result), {'order': lm_bel.order})\n",
    "    \n",
    "summarise_run(\"mkn_lm2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression-based features\n",
    "For some classification tasks compression seems to be an indication of how well it fits a model. In our case the data seems to be too much alike, and even so, there's only a little amount of data available. From a compression point of view that is. So, the feature is not as good as I hoped it would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "\n",
    "if do_run(\"zlib\"):\n",
    "    register_run(\"zlib\",\n",
    "             \"zlib compression, level 9\",\n",
    "             [])\n",
    "\n",
    "    ds = \"\"\n",
    "    bs = \"\"\n",
    "    for s, l in zip(X_training, y_training):\n",
    "        if l == \"DUT\":\n",
    "            ds += l\n",
    "        else:\n",
    "            bs += l\n",
    "            \n",
    "    result = []\n",
    "    for s in X_dev:    \n",
    "        \n",
    "        len_dut = len(zlib.compress((ds + s).encode('utf-8'),9))\n",
    "        len_bel = len(zlib.compress((bs + s).encode('utf-8'),9))\n",
    "        \n",
    "        if len_bel > len_dut:\n",
    "            result.append(\"DUT\")\n",
    "        elif len_bel < len_dut:\n",
    "            result.append(\"BEL\")\n",
    "        else:\n",
    "            len_dut_a = len(zlib.compress((ds + ds + bs+ s).encode('utf-8'),9))\n",
    "            len_bel_a = len(zlib.compress((bs + bs + ds + s).encode('utf-8'),9))\n",
    "            if len_bel_a > len_dut_a:\n",
    "                result.append(\"DUT\")\n",
    "            elif len_bel_a < len_dut_a:\n",
    "                result.append(\"BEL\")\n",
    "            else:\n",
    "                score = random.randint(0,1)\n",
    "                result.append((\"DUT\", \"BEL\")[score > 0])\n",
    "    \n",
    "    update_stats(\"zlib\", y_dev, np.array(result), {})\n",
    "    \n",
    "summarise_run(\"zlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles\n",
    "Yes. Ensembles. The icing to the cake, the booster shot that will get you first place. Probably not me, but someone might. We are going to combine all sorts of features and learners, sacrifice a goat, and hope for an ever beter model. \n",
    "M A G I C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predictions: [[weight1, predictions1], ..., [weightn, predictionsn]]\n",
    "# DUT = -1.0, BEL = 1.0\n",
    "def ensemble(y_true, y_predictions):\n",
    "    for _, preds in y_predictions:\n",
    "        if len(preds) != len(y_true):\n",
    "            print(\"WTF\")\n",
    "    \n",
    "    scores = []\n",
    "    for i in range(len(y_true)):\n",
    "        score = 0\n",
    "        #print(score)\n",
    "        for weight, preds in y_predictions:\n",
    "            score += weight * (-1.0, 1.0)[preds[i] == \"BEL\"]\n",
    "            #print(\"\\t\", score)\n",
    "        #print(score, (\"DUT\", \"BEL\")[score > 0], \"\\n\")\n",
    "        if score == 0.0:\n",
    "            score = random.randint(0,1)\n",
    "        scores.append((\"DUT\", \"BEL\")[score > 0])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ensemble([1,2,3,4], [[2.5,[\"DUT\", \"BEL\", \"BEL\", \"DUT\"]], [1.3, [\"BEL\", \"BEL\", \"DUT\", \"DUT\"]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counts: rfo 0.658\n",
    "\n",
    "tfidf: mnb 0.698\n",
    "\n",
    "pos: sgd 0.694\n",
    "\n",
    "llh: rfo 0.676\n",
    "\n",
    "embedding: ftt 0.692\n",
    "\n",
    "lm: mkn 0.666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = \"DUT\"\n",
    "#(0, 1)[a == \"BEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# voting classifier\n",
    "def find_random_weights():\n",
    "    accs = []\n",
    "    best_acc = 0\n",
    "    for i in range(100000):\n",
    "        best_predictions = []\n",
    "        for method in _run_stats.keys():\n",
    "            best_predictions.append([random.randint(0,100), _run_stats[method]['best_predictions']])\n",
    "\n",
    "        acc = accuracy_score(y_dev, ensemble(y_dev, best_predictions))\n",
    "        accs.append([acc, [row[0] for row in best_predictions]])\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            weights = [row[0] for row in best_predictions]\n",
    "            norm_weights = [float(i)/sum(weights) for i in weights]\n",
    "            print(\"%.3f\" % acc, end=\"\\t\")\n",
    "            for w, n in list(zip(norm_weights, _run_stats.keys())):\n",
    "                print(\"%.2f %s\"  % (w, n), end=\"\\t\")\n",
    "            print()\n",
    "    return accs\n",
    "\n",
    "# majority baseline\n",
    "def find_uniform_weights():\n",
    "    accs = []\n",
    "    best_predictions = []\n",
    "    for method in _run_stats.keys():\n",
    "        best_predictions.append([1, _run_stats[method]['best_predictions']])\n",
    "\n",
    "    accs.append([accuracy_score(y_dev, ensemble(y_dev, best_predictions)), [row[0] for row in best_predictions]])\n",
    "    return accs\n",
    "\n",
    "print()\n",
    "\n",
    "from operator import itemgetter\n",
    "best_random_score = max(find_random_weights(),key=itemgetter(0))\n",
    "print(best_random_score)\n",
    "print(list(zip(best_random_score[1], _run_stats.keys())))\n",
    "\n",
    "from operator import itemgetter\n",
    "best_uniform_score = max(find_uniform_weights(),key=itemgetter(0))\n",
    "print(best_uniform_score)\n",
    "print(list(zip(best_uniform_score[1], _run_stats.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"DUT\", \"BEL\"])\n",
    "\n",
    "print(\"\\t\" + \"\\t\".join(_run_stats.keys()))\n",
    "for keya in _run_stats.keys():\n",
    "    a = le.transform(_run_stats[keya]['best_predictions'])\n",
    "    \n",
    "    print(keya, end=\"\\t\")\n",
    "    \n",
    "    for keyb in _run_stats.keys():\n",
    "        b = le.transform(_run_stats[keyb]['best_predictions'])\n",
    "        \n",
    "        print(\"%.4f\" % np.corrcoef(a,b)[0][1], end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONLY COMBINE WHEN THERE'S A LOW CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#    for alpha in tqdm(10.0 ** -np.arange(1, 7), desc=\"alpha\"):\n",
    "#        for hls in tqdm([(5,2), (5,5), (10,2), (10,5), (50,2), (50,5), (50,10)], desc=\"hls\"):\n",
    "\n",
    "if do_run(\"mlp1\"):\n",
    "    mlp1 = TfidfVectorFeatures(\"mlp1\", \"c&w n-grams, tfidf, mlp adam\", MLPClassifier(solver='adam', alpha=alpha, hidden_layer_sizes=hls, random_state=1)).run()\n",
    "summarise_run(\"mlp1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "if do_run(\"mlp1\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "         print(k, LLHbasedFeatures(\"mlp1\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"c&w n-grams, llh, xgboost\", \n",
    "                                               MLPClassifier(solver='adam', random_state=1), \n",
    "                                               k=k).run())\n",
    "summarise_run(\"mlp1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "if do_run(\"mlp1\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "         print(k, LLHbasedFeatures(\"mlp1\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"c&w n-grams, llh, xgboost\", \n",
    "                                               MLPClassifier(solver='saga', random_state=1), \n",
    "                                               k=k).run())\n",
    "summarise_run(\"mlp1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if do_run(\"log_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "         print(k, LLHbasedFeatures(\"log_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"c&w n-grams, llh, logit\", \n",
    "                                               SGDClassifier(loss=\"log\"), \n",
    "                                               k=k).run())\n",
    "summarise_run(\"log_llh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_run(\"pct_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "         print(k, LLHbasedFeatures(\"pct_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                               \"c&w n-grams, llh, perceptron\", \n",
    "                                               SGDClassifier(loss=\"perceptron\"), \n",
    "                                               k=k).run())\n",
    "summarise_run(\"pct_llh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "if do_run(\"bag1\"):\n",
    "    bag1 = TfidfVectorFeatures(\"bag1\", \"c&w n-grams, tfidf, bagging svc\", BaggingClassifier(LinearSVC(), n_estimators=10, max_samples=0.1)).run()\n",
    "summarise_run(\"bag1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#    for alpha in tqdm(10.0 ** -np.arange(1, 7), desc=\"alpha\"):\n",
    "#        for hls in tqdm([(5,2), (5,5), (10,2), (10,5), (50,2), (50,5), (50,10)], desc=\"hls\"):\n",
    "\n",
    "if do_run(\"mlp1\"):\n",
    "    mlp1 = TfidfVectorFeatures(\"mlp1\", \"c&w n-grams, tfidf, mlp adam\", MLPClassifier(solver='adam', alpha=alpha, hidden_layer_sizes=hls, random_state=1)).run()\n",
    "summarise_run(\"mlp1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select k-best character and word n-gram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "if do_run(\"rfo2\"):\n",
    "    \n",
    "    register_run(\"rfo1\",\n",
    "             \"binary loglikelihood-based vectors on word n-grams, used in a random forest setting\",\n",
    "             ['count'])\n",
    " \n",
    "    print(\"Extracting features\")\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,6),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\")\n",
    "    X_training_vec = vectorizer.fit_transform(X_training)\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_training_vect.shape)\n",
    "\n",
    "    print(\"Extracting from test data\")\n",
    "    X_dev_vec = vectorizer.transform(X_dev)\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_dev_vect.shape)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    for k in range(1,100000, 1000):\n",
    "\n",
    "\n",
    "        print(\"Extracting %d best features by a chi-squared test\" % k)\n",
    "        ch2 = SelectKBest(chi2, k=k)\n",
    "        #print(chi2(X_training_vect, y_training))\n",
    "        X_training_vect = ch2.fit_transform(X_training_vec, y_training)\n",
    "        X_dev_vect = ch2.transform(X_dev_vec)\n",
    "#         print(\"n_samples: %d, n_features: %d\" % X_training_vect.shape)\n",
    "#         print(\"n_samples: %d, n_features: %d\" % X_dev_vect.shape)\n",
    "\n",
    "\n",
    "        clf = RandomForestClassifier(max_depth=2)\n",
    "        clf.fit(X_training_vect, y_training)\n",
    "        print(k, clf.score(X_dev_vect, y_dev ))\n",
    "    \n",
    "#     for min_cn in tnrange(1,8, desc=\"min char ngram\"):\n",
    "#         for max_cn in tnrange(min_cn, 8, desc=\"max char ngram\"):\n",
    "\n",
    "#             for min_n in tnrange(1,6, desc=\"min word ngram\"):\n",
    "#                 for max_n in tnrange(min_n,6, desc=\"max word ngram\"):\n",
    "\n",
    "#                     steps = [('char', )),\n",
    "#                              ('words', TfidfVectorizer(analyzer='word', ngram_range=(min_n,max_n),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))\n",
    "#                             ]\n",
    "\n",
    "#                     union = FeatureUnion(steps)\n",
    "\n",
    "#                     pipeline = Pipeline([\n",
    "#                         ('union', union),\n",
    "#                         ('rfo', RandomForestClassifier()),\n",
    "#                     ])\n",
    "\n",
    "#                     model = pipeline.fit(X_training, y_training)\n",
    "#                     print(model)\n",
    "\n",
    "#                     ch2 = SelectKBest(chi2, k=1000)\n",
    "#                     X_training_new = ch2.fit_transform(X_training, y_training)\n",
    "#                     X_dev_new = ch2.transform(X_dev)\n",
    "\n",
    "#                     y_pred = model.predict(X_dev)\n",
    "\n",
    "#                     update_stats(\"rfo2\", y_dev, y_pred, {'min_cn': min_cn, 'max_cn': max_cn, 'min_n': min_n, 'max_n': max_n})\n",
    "\n",
    "summarise_run(\"rfo2\")       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_run(\"lsc_llh\"):\n",
    "    for k in [100, 1000, 10000, 100000]:\n",
    "        for C in [0.1, 0.5, 1.0]:\n",
    "            model = LLHbasedFeatures(\"lsc_llh\", X_training, y_training, X_dev, y_dev, \n",
    "                                                   \"c&w n-grams, llh, linear svc\", \n",
    "                                                   LinearSVC(C=C), \n",
    "                                                   k=k)\n",
    "            model_acc = model.run()\n",
    "            print(k, C, model_acc)\n",
    "summarise_run(\"lsc_llh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlp\n",
    "mlp is sensitive to feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "if do_run(\"xgb1\"):\n",
    "    register_run(\"xgb1\",\n",
    "             \"character and word n-grams, with tf-idf feature vectors, used in a extreme gradient boost setting\",\n",
    "             [])\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "    parameters = {'nthread':[1], #when use hyperthread, xgboost may become slower\n",
    "                  'objective':['binary:logistic'],\n",
    "                  'learning_rate': [0.05], #so called `eta` value\n",
    "                  'max_depth': [6],\n",
    "                  'min_child_weight': [11],\n",
    "                  'silent': [1],\n",
    "                  'subsample': [0.8],\n",
    "                  'colsample_bytree': [0.7],\n",
    "                  'n_estimators': [1000], #number of trees, change it to 1000 for better results\n",
    "                  'missing':[-999],\n",
    "                  'seed': [1337]}\n",
    "\n",
    "    from sklearn.cross_validation import *\n",
    "    clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                       cv=StratifiedKFold(y_training[use], n_folds=5, shuffle=True), \n",
    "                       scoring='accuracy',\n",
    "                       verbose=2, refit=True)\n",
    "\n",
    "    #bst = clf.fit(X_training, y_training)\n",
    "    #xgb_model = xgb.XGBClassifier(nthread=1, objective='binary:logistic', learning_rate=0.05, max_depth=6, min_child_weight=11, missing=-999, n_estimators=1000, subsample=0.8, colsample_bytree=0.7)\n",
    "\n",
    "    #xgb.plot_importance(xgb_model)\n",
    "    #plt.show()\n",
    "    \n",
    "    #update_stats(\"xgb1\", y_dev, y_pred, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
