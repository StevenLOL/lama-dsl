{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "1. Use binary classification\n",
    "2. Merge training and dev data; use cross-validation\n",
    "\n",
    "3. Use char 6-grams, but also test 7+ is memory and time permits\n",
    "9. Word n-grams (1-3)\n",
    "10. Use term weighting\n",
    "\n",
    "4. nrc uses linear kernel with SVM\n",
    "5. Also consider XGB or LightGBM\n",
    "8. Logistic regression with L2 reg and C=1\n",
    "\n",
    "6. Blacklists/whitelists\n",
    "7. Dimensionality reduction\n",
    "\n",
    "11. Create confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read provisional training material\n",
    "The official data will be released at the end of March. It will probably be the BTI data, so in order to avoid all forms of contamination, we will use a different set. Our data consists of SUBTIEL data, with both Flemish and Netherlandic Dutch subtitles. It requires some preprocessing to convert the files from PAC and STL to SRT. We run this conversion offline, as it also contains some manual steps. And it probably is different from the official data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files are converted to plain text, so we remove all information pertaining to time, colour of the text, and font styles. For the conversion of pac files we run this mess of a grep:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "for L in VL NL; do find ./*/${L}/ -iname \"*.pac\" -exec ./unpac {} \\; | grep -v \"\\\"\\| ' *$\\|\\\\$\\|\\&\\|)\\|;\\|%\\|^ .[[:space:]]*$\\|^ ..[[:space:]]*$\\|^ . .[[:space:]]$\\|^[[:space:]]*$\" | sed 's/<\\|>//g' | grep -v \"^[[:space:]]*.$\\|^[[:space:]]*..$\\|^[[:space:]]*.[[:space:]].[[:space:]]*$\\|^[[:space:]]*..[[:space:]]..[[:space:]]*$\\|^[[:space:]]*..[[:space:]].[[:space:]]*$\\|^[[:space:]]*.[[:space:]]..[[:space:]]*$\\^[[:space:]]*.[[:space:]].[[:space:]]\\+.[[:space:]]*$\" | grep -v \"^[[:space:]]*.$\\|^[[:space:]]*..$\\|^[[:space:]]*.[[:space:]].[[:space:]]*$\\|^[[:space:]]*..[[:space:]]..[[:space:]]*$\\|^[[:space:]]*..[[:space:]].[[:space:]]*$\\|^[[:space:]]*.[[:space:]]..[[:space:]]*$\\^[[:space:]]*.[[:space:]].[[:space:]]\\+.[[:space:]]*$\\|BTI\\|Broadcast\\|Title:\\|title:\\|Story:\\|story:\\|Story:\\|TITLE:\\|CONFIG:\\|Config:\\|config:\" > ${L}.unpac; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The stl files are cleaner; we extract the info with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "for L in VL NL; do find ./*/${L}/ -iname \"*.stl\" -printf '%P\\n' -execdir python2 ~/Programming/stl2srt/to_srt.py {} ~/Programming/lama-dsl/data/${L}srt/{} \\; ;  for f in ~/Programming/lama-dsl/data/${L}srt/*.stl; do grep -v \"\\-\\->\\|^[[:space:]]*[[:digit:]]\\+$\\|^[[:space:]]*$\" $f | tail -n +4 ; done > ${L}.unstl; done\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that the Flemish data does not have any STL files. Ah well.\n",
    "The first stats:\n",
    "```\n",
    "wc ?L.all   \n",
    "  384631  2770783 15103475 NL.all\n",
    "  296689  2641861 14050991 VL.all\n",
    "```\n",
    "The next step is to run the files through ucto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ucto\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PICKLE RICK!!!\n"
     ]
    }
   ],
   "source": [
    "ucto_config = \"tokconfig-nld\"\n",
    "\n",
    "vl_text = []\n",
    "try:\n",
    "    with open('data/VL.all.pickle', 'rb') as f:\n",
    "        vl_text = pickle.load(f)\n",
    "except IOError:    \n",
    "    vl_tokeniser = ucto.Tokenizer(ucto_config)\n",
    "    with open('data/VL.all', 'r') as f:\n",
    "        for line in f:\n",
    "            vl_tokeniser.process(line)\n",
    "    print(\"All Flemish data has been tokenised.\")\n",
    "\n",
    "    current_line = []\n",
    "    for token in vl_tokeniser:\n",
    "        current_line.append(str(token))\n",
    "        if token.isendofsentence():\n",
    "            vl_text.append(\" \".join(current_line))\n",
    "            current_line = []\n",
    "    print(\"All Flemish data has been converted to sentences.\")\n",
    "    \n",
    "    with open('data/VL.all.pickle', 'wb') as f:\n",
    "        pickle.dump(vl_text, f, pickle.HIGHEST_PROTOCOL)    \n",
    "    print(\"All Flemish sentences have been written to a pickle.\")\n",
    "\n",
    "nl_text = []\n",
    "try:\n",
    "    with open('data/NL.all.pickle', 'rb') as f:\n",
    "        nl_text = pickle.load(f)\n",
    "except IOError:\n",
    "    nl_tokeniser = ucto.Tokenizer(ucto_config)\n",
    "    with open('data/NL.all', 'r') as f:\n",
    "        for line in f:\n",
    "            nl_tokeniser.process(line)        \n",
    "    print(\"All Netherlandic data has been tokenised.\")     \n",
    "\n",
    "    current_line = []\n",
    "    for token in nl_tokeniser:\n",
    "        current_line.append(str(token))\n",
    "        if token.isendofsentence():\n",
    "            nl_text.append(\" \".join(current_line))\n",
    "            current_line = []\n",
    "    print(\"All Netherlandic data has been converted to sentences.\")\n",
    "    \n",
    "    with open('data/NL.all.pickle', 'wb') as f:\n",
    "        pickle.dump(nl_text, f, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"All Netherlandic sentences have been written to a pickle.\")\n",
    "print(\"PICKLE RICK!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "xl_text = vl_text + nl_text\n",
    "xl_labels = ['vl'] * len(vl_text) + ['nl'] * len(nl_text)\n",
    "\n",
    "combined = list(zip(xl_text, xl_labels))\n",
    "random.shuffle(combined)\n",
    "xl_text[:], xl_labels[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 438070 Flemish texts and 484697 Netherlandic texts. Total: 922767\n",
      "Mean length Flemish sentence:  7.059401465519209\n",
      "Mean length Dutch sentence:    6.848851963185248\n",
      "Mean length all sentences:     6.948807228693701\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(len(vl_text)) + \" Flemish texts and \" + str(len(nl_text)) + \" Netherlandic texts. Total: \" + str(len(xl_text)))\n",
    "print(\"Mean length Flemish sentence: \", sum([len(x.split()) for x in vl_text])/len(vl_text))\n",
    "print(\"Mean length Dutch sentence:   \", sum([len(x.split()) for x in nl_text])/len(nl_text))\n",
    "print(\"Mean length all sentences:    \", sum([len(x.split()) for x in xl_text])/len(xl_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have any test data, but we will extensively use cross-validation to see our progress (if any)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1: Traditional classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification with counts\n",
    "Here we use character and word $n$-grams, and a linear kernel with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('char', CountVectorizer(analyzer='char', ngram_range=(3,3))),\n",
    "         ('words', CountVectorizer(analyzer='word', ngram_range=(3,3),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"))]\n",
    "\n",
    "union = FeatureUnion(steps)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('union', union),\n",
    "    ('svc', SVC(kernel='linear')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(xl_text):\n",
    "    print('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "\n",
    "    param_grid = dict(features__univ_select__k=[1, 2],\n",
    "                      svm__C=[0.1, 1, 10])\n",
    "    \n",
    "    #grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=10)\n",
    "    #grid_search.fit(alltrainingmaterial[train], alllabels[train]).score(alltrainingmaterial[test], alllabels[test])\n",
    "    #    for train, test in k_fold.split(alltrainingmaterial)]\n",
    "    \n",
    "    print(\"Fitting model on data\") xl_text[train_indices] xl_text[test_indices]\n",
    "    prediction = pipeline.fit(xl_text[train_indices], xl_labels[train_indices])\n",
    "    print(\"Predict the labels on test data\")\n",
    "    prediction = pipeline.predict(xl_text[test_indices])\n",
    "    print(\"Score\")\n",
    "    pipeline.score(xl_text[test_indices], xl_labels[test_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fasttext classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ecabbe85589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bla.train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "\n",
    "\n",
    "with open('bla.train.txt', 'w') as f:\n",
    "    for line, label in zip(xl_text, xl_labels):\n",
    "        f.write(line + \" __language__\" + label + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "ft_classifier = fasttext.supervised('bla.train.txt', 'model', \n",
    "                                    min_count=1, \n",
    "                                    word_ngrams=3, \n",
    "                                    minn=7, \n",
    "                                    maxn=7, \n",
    "                                    thread=2, \n",
    "                                    label_prefix='__language__')\n",
    "ft_predictions = ft_classifier.predict(xl_text[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gensim\n",
    "#from gensim.models.fasttext import FastText as FT_gensim\n",
    "#\n",
    "#ftg_model = FT_gensim(sentences=[x.split() for x in xl_text[0:9000]], size=250, min_count=1, min_n=7, max_n=7, word_ngrams=1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
